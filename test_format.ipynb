{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa='bbb'\n",
    "def func():\n",
    "  print('DDD',end=\"\\n\")\n",
    "def func2():\n",
    "    #print('DDD',end=\"\\n\")\n",
    "    print(\"EEE\")\n",
    "\n",
    "\n",
    "aaa = 'bbb'\n",
    "\n",
    "\n",
    "def func():\n",
    "  print('DDD', end=\"\\n\")\n",
    "\n",
    "\n",
    "def func2():\n",
    "    # print('DDD',end=\"\\n\")\n",
    "    print(\"EEE\")\n",
    "\n",
    "\n",
    "aaa = 'bbb'\n",
    "\n",
    "\n",
    "def func():\n",
    "  print('DDD', end=\"\\n\")\n",
    "\n",
    "\n",
    "def func2():\n",
    "    # print('DDD',end=\"\\n\")\n",
    "    print(\"EEE\")\n",
    "\n",
    "\n",
    "def read_arg3():\n",
    "    with open('arg3.csv', 'r') as f:\n",
    "        file = f.read().splitlines()\n",
    "    No_path = int(file[0])  # pathの数\n",
    "    para_n = file[1].split(',')  # 変数の名前\n",
    "    para_v = [float(n) for n in file[2].split(',')]  # 初期値\n",
    "    para_min = [float(n) for n in file[3].split(',')]  # 最小値\n",
    "    para_max = [float(n) for n in file[4].split(',')]  # 最大値\n",
    "    # vary bool()だとだめだったので文字列の比較でブール値に変換する\n",
    "    para_va = [n == 'True' for n in file[5].split(',')]\n",
    "    feff_l = file[6].split(',')  # feffファイルのパス\n",
    "    para2_u_list = [n == 'True' for n in file[7].split(',')]  # C3,C4,Eiを使用するか\n",
    "    para2_n = file[8].split(',')  # C3,C4,Eiの名前\n",
    "    para2_v = [float(n) for n in file[9].split(',')]  # C3,C4,Ei初期値\n",
    "    para2_min = [float(n) for n in file[10].split(',')]  # C3,C4,Ei最小値\n",
    "    para2_max = [float(n) for n in file[11].split(',')]  # C3,C4,Ei最大値\n",
    "    para2_va = [n == 'True' for n in file[12].split(',')]  # C3,C4,Ei vary\n",
    "    para_name = [para_n[0:5], para_n[5:10],\n",
    "                 para_n[10:15], para_n[15:20]]  # 2d listにする\n",
    "    para_value = [para_v[0:5], para_v[5:10], para_v[10:15], para_v[15:20]]\n",
    "    para_min = [para_min[0:5], para_min[5:10],\n",
    "                para_min[10:15], para_min[15:20]]\n",
    "    para_max = [para_max[0:5], para_max[5:10],\n",
    "                para_max[10:15], para_max[15:20]]\n",
    "    para_variable = [para_va[0:5], para_va[5:10],\n",
    "                     para_va[10:15], para_va[15:20]]\n",
    "    para2_name = [para2_n[0:5], para2_n[5:10], para2_n[10:15]]\n",
    "    para2_value = [para2_v[0:5], para2_v[5:10], para2_v[10:15]]\n",
    "    para2_min = [para2_min[0:5], para2_min[5:10], para2_min[10:15]]\n",
    "    para2_max = [para2_max[0:5], para2_max[5:10], para2_max[10:15]]\n",
    "    para2_variable = [para2_va[0:5], para2_va[5:10], para2_va[10:15]]\n",
    "    return No_path, para_name, para_value, para_min, para_max, para_variable, feff_l, para2_u_list, para2_name, para2_value, para2_min, para2_max, para2_variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anaconda 3\n",
    "# conda 23.3.1\n",
    "# python 3.9.16\n",
    "# xraylarch 0.9.59\n",
    "\n",
    "from numba import jit\n",
    "import larch as la\n",
    "from larch.fitting import param, param_group\n",
    "from larch import io, xafs, Group, Interpreter, xray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as ny\n",
    "from .JoblibProcessFefffitBlock import process_calc_fefffit\n",
    "from joblib import Parallel, delayed\n",
    "from os import environ\n",
    "import concurrent.futures\n",
    "from os import cpu_count\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path  # added by fujikawa on 20222/12/23\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import itertools\n",
    "from IPython.display import display\n",
    "from ipywidgets import (interact, BoundedFloatText, interactive_output, HBox, VBox, Label,\n",
    "                        Text, IntSlider, Layout, Checkbox, SelectMultiple, BoundedIntText,\n",
    "                        Dropdown, Button, Textarea, Select)\n",
    "\n",
    "# ベンチマーク用モジュール\n",
    "# Added by Fujikawa\n",
    "import time\n",
    "import datetime\n",
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "# logファイルの作成  Implemented by fujikawa since 2022.Sep\n",
    "# loggerの設定basicConfigはimport larch以上で行わないと動作しない場合がある\n",
    "# Added by Fujikawa\n",
    "import logging\n",
    "logger = logging.getLogger('XAFSanalysisFunc')\n",
    "# 出力レベルの設定\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "logger.setLevel(logging.INFO)\n",
    "# ハンドラの生成\n",
    "log_date = datetime.datetime.now()\n",
    "handler = logging.FileHandler(\n",
    "    f'XAFSanalysisFunc{log_date.strftime(\"%Y%m%d%H%M%S\")}.log')\n",
    "# ロガーにハンドラを登録\n",
    "logger.addHandler(handler)\n",
    "# フォーマッタの生成\n",
    "fmt = logging.Formatter(\n",
    "    '%(asctime)s %(module)s.%(funcName)s %(lineno)s[%(levelname)s]: %(message)s')\n",
    "\n",
    "#\n",
    "# 処理速度向上のためのライブラリ START\n",
    "#\n",
    "# Added by Fujikawa\n",
    "# CPUのスレッド総数\n",
    "# cpu_count()/2がコア数\n",
    "# BLASのスレッド制限はコア数の多いCPUでマルチプロセスのパフォーマンスが上がる\n",
    "# Need to arrange this code for prevent over-subscription caused by BLAS above import numpy\n",
    "# Added by Fujikawa\n",
    "N_THREADS = '1'\n",
    "environ['OMP_NUM_THREADS'] = N_THREADS\n",
    "environ['OPENBLAS_NUM_THREADS'] = N_THREADS\n",
    "environ['MKL_NUM_THREADS'] = N_THREADS\n",
    "environ['VECLIB_MAXIMUM_THREADS'] = N_THREADS\n",
    "environ['NUMEXPR_NUM_THREADS'] = N_THREADS\n",
    "# FTとFEFFのフィッティング用マルチプロセッシングライブラリ\n",
    "# Added for performance acceleration\n",
    "# マルチプロセッシング用のFEFFフィッティングサブプロセス関数\n",
    "#\n",
    "# 処理速度向上のためのライブラリ END\n",
    "#\n",
    "\n",
    "# NOTE:環境変数'OMP_NUM_THREADS'の変更より後にnumpyはimportする\n",
    "\n",
    "# XAFS解析ライブラリxraylarch\n",
    "\n",
    "PREFIXES = ['norm', 'chik', 'FT', 'Fit']\n",
    "\n",
    "#\n",
    "# テスト環境用のパラメータ START\n",
    "#\n",
    "# 評価機能のON（True）、OFF\n",
    "PROFILER = False  # for profiler on 2202.11.15 GUIで変更可能。\n",
    "BENCH = True  # for benchmark on 2202.11.15\n",
    "# BENCH = False\n",
    "# メモリー監視のため\n",
    "MEMORY_ASSESSMENT = True  # for momory monitor on 2022.11.17\n",
    "# MEMORY_ASSESSMENT = False\n",
    "\n",
    "# 最適化処理のON(True）、OFF(False)\n",
    "# THREAD_SAVE = True # for threading of save text file on 2202.11.15 GUIで変更可能。\n",
    "THREAD_SAVE = False\n",
    "\n",
    "BINARY_SAVE = True  # for save files as binary files on 2202.11.17　 GUIで変更可能。\n",
    "# BINARY_SAVE = False\n",
    "\n",
    "# FEFFfフィットの初期値の最適化をすべてのデータにするか、始めの一つ目のデータだけにするか。\n",
    "# GUIで変更可能。\n",
    "OPTIMIZE_FIT = True  # Optimization of initial FEFFit variables for all data\n",
    "# OPTIMIZE_FIT = False\n",
    "\n",
    "MULTIPROCESS_FIT = True  # for multiprocessing of FEFFit()  GUIで変更可能。\n",
    "# MULTIPROCESS_FIT = False\n",
    "\n",
    "MULTIPROCESS_FT = True  # for multiprocessing of XAFSana_all()  GUIで変更可能。\n",
    "# MULTIPROCESS_FT = False\n",
    "\n",
    "# ファイルのテキストでのセーブとバイナリでのセーブは併用できない\n",
    "if THREAD_SAVE and BINARY_SAVE is True:\n",
    "    THREAD_SAVE = False\n",
    "    logger.warning(\n",
    "        \"Only THREAD_SAVE was changed to False, because both THREAD_SAVE and BINARY_SAVE are True.\\nYou may assign False to either of these.\")\n",
    "\n",
    "# inital number of cpu cores provided with multiprocessing of FEFFfit()\n",
    "MULTIPROCESS_FIT_CPU_CORE = 2\n",
    "# initial number of cpu cores provided with multiprocessing of XAFSana_all()\n",
    "MULTIPROCESS_FT_CPU_CORE = 2\n",
    "#\n",
    "# テスト環境用のパラメータ END\n",
    "#\n",
    "\n",
    "\n",
    "# xraylarchのインタープリター環境のインスタンス\n",
    "session = Interpreter()\n",
    "\n",
    "# arg2.csvを配置している場合はそちらが優先される\n",
    "# 各種パラメーターの初期値\n",
    "ipreE1 = -200  # pre-edge line range\n",
    "ipreE2 = -50\n",
    "ipostE1 = 150  # post-edge line range\n",
    "ipostE2 = 400\n",
    "inormO = 3  # normalization order\n",
    "irbkg1 = 1.0  # Rbkg\n",
    "ikmin1 = 0.0  # spline range in k\n",
    "ikmax1 = 15.0\n",
    "ikmin2 = 3.0  # FT range in k\n",
    "ikmax2 = 9.0\n",
    "irmin1 = 1.0  # Fitting range in r\n",
    "irmax1 = 3.0\n",
    "ikw = 2  # Fitting k-weight\n",
    "\n",
    "F_initial = False  # Paramsetとpathlistの初期値をargファイルの値にするかどうかの判定\n",
    "\n",
    "# jupyternotebookで連続XAFSスペクトル解析するための関数\n",
    "\n",
    "# pythonのホームディレクトリに以下のファイルを生成する。\n",
    "# arg1.csv ファイルパス等\n",
    "# arg2.csv　解析パラメータ\n",
    "# arg3.csv　フィッティングパスの設定\n",
    "\n",
    "# 変数を渡すためのcsvファイル作成(もう使っていない)\n",
    "\n",
    "\n",
    "def save_arg(a):\n",
    "    with open('arg.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(a)\n",
    "    return a\n",
    "\n",
    "# ファイルパスとか保存したcsvファイルを読み込む\n",
    "\n",
    "\n",
    "def read_arg1():  # modified by Fujikawa\n",
    "    with open('arg1.csv', 'r') as f:\n",
    "        file1 = f.read()\n",
    "    file = file1.split(',')\n",
    "    filelist = glob.glob(file[0]+'/'+file[1]+file[2])\n",
    "    filenamelist = []\n",
    "    savefileD = file[3].rstrip('\\n')\n",
    "    for fn in filelist:\n",
    "        filenamelist.append(os.path.basename(fn))\n",
    "    return filelist, filenamelist, savefileD\n",
    "\n",
    "# 解析パラメータ読み込む\n",
    "\n",
    "\n",
    "def read_arg2():\n",
    "    with open('arg2.csv', 'r') as f:\n",
    "        file2 = f.read()\n",
    "    file = file2.split(',')\n",
    "    readfile = file[0].split(':')\n",
    "    preE1 = float(file[1])  # pre edge range\n",
    "    preE2 = float(file[2])\n",
    "    postE1 = float(file[3])  # normalization reange\n",
    "    postE2 = float(file[4])\n",
    "    e01 = float(file[5])  # E0\n",
    "    normO = float(file[6])  # normalization order\n",
    "    rbkg1 = float(file[7])\n",
    "    kmin1 = float(file[8])  # spline range in k\n",
    "    kmax1 = float(file[9])\n",
    "    kmin2 = float(file[10])  # forward FT range in k\n",
    "    kmax2 = float(file[11])\n",
    "    rmin1 = float(file[12])  # fitting range in r\n",
    "    rmax1 = float(file[13])\n",
    "    kw2 = float(file[14])  # fitting k-weight\n",
    "    return readfile, preE1, preE2, postE1, postE2, e01, normO, rbkg1, kmin1, kmax1, kmin2, kmax2, rmin1, rmax1, kw2\n",
    "\n",
    "# フィッティングパスの設定読み込む\n",
    "\n",
    "\n",
    "def read_arg3():\n",
    "    with open('arg3.csv', 'r') as f:\n",
    "        file = f.read().splitlines()\n",
    "    No_path = int(file[0])  # pathの数\n",
    "    para_n = file[1].split(',')  # 変数の名前\n",
    "    para_v = [float(n) for n in file[2].split(',')]  # 初期値\n",
    "    para_min = [float(n) for n in file[3].split(',')]  # 最小値\n",
    "    para_max = [float(n) for n in file[4].split(',')]  # 最大値\n",
    "    # vary bool()だとだめだったので文字列の比較でブール値に変換する\n",
    "    para_va = [n == 'True' for n in file[5].split(',')]\n",
    "    feff_l = file[6].split(',')  # feffファイルのパス\n",
    "    para2_u_list = [n == 'True' for n in file[7].split(',')]  # C3,C4,Eiを使用するか\n",
    "    para2_n = file[8].split(',')  # C3,C4,Eiの名前\n",
    "    para2_v = [float(n) for n in file[9].split(',')]  # C3,C4,Ei初期値\n",
    "    para2_min = [float(n) for n in file[10].split(',')]  # C3,C4,Ei最小値\n",
    "    para2_max = [float(n) for n in file[11].split(',')]  # C3,C4,Ei最大値\n",
    "    para2_va = [n == 'True' for n in file[12].split(',')]  # C3,C4,Ei vary\n",
    "    para_name = [para_n[0:5], para_n[5:10],\n",
    "                 para_n[10:15], para_n[15:20]]  # 2d listにする\n",
    "    para_value = [para_v[0:5], para_v[5:10], para_v[10:15], para_v[15:20]]\n",
    "    para_min = [para_min[0:5], para_min[5:10],\n",
    "                para_min[10:15], para_min[15:20]]\n",
    "    para_max = [para_max[0:5], para_max[5:10],\n",
    "                para_max[10:15], para_max[15:20]]\n",
    "    para_variable = [para_va[0:5], para_va[5:10],\n",
    "                     para_va[10:15], para_va[15:20]]\n",
    "    para2_name = [para2_n[0:5], para2_n[5:10], para2_n[10:15]]\n",
    "    para2_value = [para2_v[0:5], para2_v[5:10], para2_v[10:15]]\n",
    "    para2_min = [para2_min[0:5], para2_min[5:10], para2_min[10:15]]\n",
    "    para2_max = [para2_max[0:5], para2_max[5:10], para2_max[10:15]]\n",
    "    para2_variable = [para2_va[0:5], para2_va[5:10], para2_va[10:15]]\n",
    "    return No_path, para_name, para_value, para_min, para_max, para_variable, feff_l, para2_u_list, para2_name, para2_value, para2_min, para2_max, para2_variable\n",
    "\n",
    "# フィッティングに使った変数を保存する\n",
    "\n",
    "\n",
    "def save_args():\n",
    "    with open('arg1.csv', 'r') as f:\n",
    "        file1 = f.read()\n",
    "    file = file1.split(',')\n",
    "    fileD = file[0]\n",
    "    fileP = file[1]\n",
    "    fileE = file[2]\n",
    "    saveD = file[3].rstrip('\\n')\n",
    "    readfile, preE1, preE2, postE1, postE2, e01, normO, rbkg1, kmin1, kmax1, kmin2, kmax2, rmin1, rmax1, kw2 = read_arg2()\n",
    "    No_path, para_name, para_value, para_min, para_max, para_variable, feff_l, para2_u_l, para2_name, para2_value, para2_min, para2_max, para2_variable = read_arg3()\n",
    "    para_name = para_name[0][0:No_path]+para_name[1][0:No_path] + \\\n",
    "        para_name[2][0:No_path]+para_name[3][0:No_path]\n",
    "    para_value = para_value[0][0:No_path]+para_value[1][0:No_path] + \\\n",
    "        para_value[2][0:No_path]+para_value[3][0:No_path]\n",
    "    para_min = para_min[0][0:No_path]+para_min[1][0:No_path] + \\\n",
    "        para_min[2][0:No_path]+para_min[3][0:No_path]\n",
    "    para_max = para_max[0][0:No_path]+para_max[1][0:No_path] + \\\n",
    "        para_max[2][0:No_path]+para_max[3][0:No_path]\n",
    "    para_variable = para_variable[0][0:No_path]+para_variable[1][0:No_path] + \\\n",
    "        para_variable[2][0:No_path]+para_variable[3][0:No_path]\n",
    "    feff_l = feff_l[0:No_path]\n",
    "    if para2_u_l[0]:\n",
    "        para_name.extend(para2_name[0][0:No_path])\n",
    "        para_value.extend(para2_value[0][0:No_path])\n",
    "        para_min.extend(para2_min[0][0:No_path])\n",
    "        para_max.extend(para2_max[0][0:No_path])\n",
    "        para_variable.extend(para2_variable[0][0:No_path])\n",
    "    if para2_u_l[1]:\n",
    "        para_name.extend(para2_name[1][0:No_path])\n",
    "        para_value.extend(para2_value[1][0:No_path])\n",
    "        para_min.extend(para2_min[1][0:No_path])\n",
    "        para_max.extend(para2_max[1][0:No_path])\n",
    "        para_variable.extend(para2_variable[1][0:No_path])\n",
    "    if para2_u_l[2]:\n",
    "        para_name.extend(para2_name[2][0:No_path])\n",
    "        para_value.extend(para2_value[2][0:No_path])\n",
    "        para_min.extend(para2_min[2][0:No_path])\n",
    "        para_max.extend(para2_max[2][0:No_path])\n",
    "        para_variable.extend(para2_variable[2][0:No_path])\n",
    "    with open(saveD+'/parameters.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['E0', 'Normalization order', 'Pre-edge range', '', 'Normalization range', '',\n",
    "                        'Rbkg', 'Spline range in k', '', 'Fourier transform range', '', 'Fitting range', '', 'k-weight'])\n",
    "        writer.writerow(['e01', 'normO', 'preE1', 'preE2', 'postE1', 'postE2',\n",
    "                        'rbkg1', 'kmin1', 'kmax1', 'kmin2', 'kmax2', 'rmin1', 'rmax1', 'kw2'])\n",
    "        writer.writerow([e01, normO, preE1, preE2, postE1, postE2,\n",
    "                        rbkg1, kmin1, kmax1, kmin2, kmax2, rmin1, rmax1, kw2])\n",
    "        writer.writerow(['No of Paths'])\n",
    "        writer.writerow([No_path])\n",
    "        writer.writerow(['initial values'])\n",
    "        writer.writerow(para_name)\n",
    "        writer.writerow(para_value)\n",
    "        writer.writerow(para_min)\n",
    "        writer.writerow(para_max)\n",
    "        writer.writerow(para_variable)\n",
    "        writer.writerow(feff_l)\n",
    "        writer.writerow(['file directory', 'filename pattern',\n",
    "                        'filename extension', 'save directory'])\n",
    "        writer.writerow([fileD, fileP, fileE, saveD])\n",
    "    return rmin1\n",
    "\n",
    "# encoderの値がおかしい場合線形補完する(WSとencoderの差の四分位範囲(の4倍)を基準に異常値を探す)\n",
    "\n",
    "\n",
    "def interp_deg(aWS, aENC):\n",
    "    c_aWS = copy.copy(aWS)  # encoderの値がおかしい部分を削除した配列を作るためにコピーする\n",
    "    c_aENC = copy.copy(aENC)\n",
    "    dif_deg = [i-j for i, j in zip(c_aWS, c_aENC)]\n",
    "    q1, q3 = ny.percentile(dif_deg, [25, 75])\n",
    "    iqr = q3-q1\n",
    "    lb = q1-(iqr*4)\n",
    "    ub = q3+(iqr*4)\n",
    "    x = ny.array(dif_deg)[((dif_deg < lb) | (dif_deg > ub))]\n",
    "    i_del = []\n",
    "    for i, j in enumerate(x):\n",
    "        i_del.append(int(ny.where(dif_deg == j)[0]))\n",
    "    if len(i_del) != 0:\n",
    "        i_del = i_del[::-1]\n",
    "        for i, j in enumerate(i_del):\n",
    "            del c_aWS[j]\n",
    "            del c_aENC[j]\n",
    "        c_aWS = c_aWS[::-1]  # ny.interpは単調増加である必要があるのでひっくり返す\n",
    "        c_aENC = c_aENC[::-1]\n",
    "        for i, j in enumerate(i_del):\n",
    "            aENC[j] = ny.interp(aWS[j], c_aWS, c_aENC)\n",
    "    return aENC\n",
    "\n",
    "# conventionalとDXAFSのデータを読み込めるようにする\n",
    "# 1行目に”  9809\"(スペース2つ＋9809)があるとPFの9809フォーマットとして読み込む\n",
    "# サンプル名に9809が入っていた場合.nemファイルでも9809フォーマットとなってしまうためスペース２つも条件文に入れた\n",
    "\n",
    "\n",
    "def read_xafsdata(filepath, element=[-1]):\n",
    "    with open(filepath) as f:\n",
    "        file1line = f.readline()\n",
    "    if file1line.find('  9809') != -1:\n",
    "        with open(filepath) as f:\n",
    "            reader = f.read()\n",
    "        file = reader.splitlines()\n",
    "        points = int(file[5].split('Points=')[1])\n",
    "        block = int(file[6].split('Block =')[1])  # ブロック数\n",
    "        d = float(file[4][26:36])  # 面間隔\n",
    "        offset_s = file[12+block].split('Offset')[1]\n",
    "        offset = [float(offset_s[i*10:(i+1)*10])\n",
    "                  for i in range(int(len(offset_s)/10))]  # floatのlistに変換\n",
    "        xmu, deg1, deg2 = [], [], []\n",
    "        out = Group()\n",
    "        if file[5].find('Transmission') != -1:  # transmissionのデータ読み込み\n",
    "            for i in range(13+block, 13+block+points):\n",
    "                deg2.append(float(file[i][10:20]))\n",
    "                deg1.append(float(file[i][0:10]))\n",
    "                xmu.append(\n",
    "                    ny.log((float(file[i][30:40])-offset[2])/(float(file[i][40:50])-offset[3])))\n",
    "        elif file[5].find('Fluorescence') != -1:  # Fluolessenceのデータ読み込み\n",
    "            fluo = []\n",
    "            for i in range(13+block, 13+block+points):\n",
    "                deg2.append(float(file[i][10:20]))\n",
    "                deg1.append(float(file[i][0:10]))\n",
    "                fluo = [float(file[i][j*10+30:j*10+40]) for j in range(36)]\n",
    "                if element[0] != -1:  # 使用しない素子のデータを削除\n",
    "                    element = element[::-1]\n",
    "                    for k, kk in enumerate(element):\n",
    "                        del fluo[kk]\n",
    "                xmu.append(sum(fluo)/(float(file[i][390:400])-offset[38]))\n",
    "        angle_encoder = interp_deg(deg1, deg2)\n",
    "        out.e = ny.array([(12398.52/(2*d*ny.sin(angle/180*ny.pi)))\n",
    "                         for i, angle in enumerate(angle_encoder)])  # エネルギーの配列\n",
    "        out.xmu = ny.array(xmu)  # 吸収係数の配列\n",
    "        out.array_labels = ['e', 'xmu']  # 以下はなくてもいいけど追加するattrsはよくわからないので無視する\n",
    "        out.data = ny.stack([out.e, out.xmu])\n",
    "        out.path = filepath\n",
    "        out.header = '#' + file[2]\n",
    "        out.filename = os.path.basename(filepath)\n",
    "    else:  # col1 energy(eV), col2 xmu .nemやDXAFSのデータ\n",
    "        out = io.read_ascii(filepath, labels=['e', 'xmu'])\n",
    "    return out\n",
    "\n",
    "# arg1.csvとarg2.csvのパラメーターの通りにFTまで実行する。\n",
    "\n",
    "\n",
    "def XAFSana(pkw):\n",
    "    filelist, filenamelist, savefileD = read_arg1()\n",
    "    readfile, preE1, preE2, postE1, postE2, e01, normO, rbkg1, kmin1, kmax1, kmin2, kmax2, rmin1, rmax1, kw2 = read_arg2()\n",
    "    if pkw == -1:  # pkw=-1のときkw2で重み付けする\n",
    "        pkw = kw2\n",
    "    preEkws = dict(nnorm=normO, nvict=0, pre1=preE1,\n",
    "                   pre2=preE2, norm1=postE1, norm2=postE2)\n",
    "    d = []\n",
    "    for rf in readfile:\n",
    "        g = io.read_ascii(filelist[int(rf)], labels=['e', 'xmu'])\n",
    "        xafs.autobk(g.e, g.xmu, rbkg=rbkg1, e0=e01,\n",
    "                    pre_edge_kws=preEkws, kmin=kmin1, kmax=kmax1, group=g)\n",
    "        xafs.xftf(g, kmin=kmin2, kmax=kmax2, window='hanning',\n",
    "                  dk=1, kweight=pkw, group=g)\n",
    "        d.append(g)\n",
    "    return d\n",
    "\n",
    "\n",
    "def calc_xftf(data_number, file, rbkg1, e01, preEkws, kmin1, kmax1, kmin2, kmax2, kw2):\n",
    "    g = io.read_ascii(file, labels=['e', 'xmu'])\n",
    "    xafs.autobk(g.e, g.xmu, rbkg=rbkg1, e0=e01,\n",
    "                pre_edge_kws=preEkws, kmin=kmin1, kmax=kmax1, group=g)\n",
    "    xafs.xftf(g, kmin=kmin2, kmax=kmax2, window='hanning',\n",
    "              dk=1, kweight=kw2, group=g)\n",
    "    return data_number, g\n",
    "\n",
    "# arg1.csvで指定したすべてのファイルに対し、FTまで実行する\n",
    "\n",
    "\n",
    "def XAFSana_all(ft_cpu_core):\n",
    "    if BENCH == True:\n",
    "        with open(\"bench.txt\", mode=\"a+\") as bench_file:  # for benchmark on 2202.10.25\n",
    "            # for benchmark on 2202.10.25\n",
    "            bench_file.write(f\"XAFSana_all on {datetime.datetime.now()} \\n\")\n",
    "        start_time_xafsana = time.perf_counter()  # for benchmark on 2202.10.25\n",
    "    filelist, filenamelist, savefileD = read_arg1()\n",
    "    readfile, preE1, preE2, postE1, postE2, e01, normO, rbkg1, kmin1, kmax1, kmin2, kmax2, rmin1, rmax1, kw2 = read_arg2()\n",
    "    preEkws = dict(nnorm=normO, nvict=0, pre1=preE1,\n",
    "                   pre2=preE2, norm1=postE1, norm2=postE2)\n",
    "    if MULTIPROCESS_FT == True:  # for threading of FT on 2022.11.25\n",
    "        logger.info(\"MULTIPROCESS_FT start\")\n",
    "        d = [0 for i in range(len(filelist))]\n",
    "        # joblibによるマルチプロセス処理\n",
    "        for result in Parallel(n_jobs=ft_cpu_core)([delayed(calc_xftf)(data_number, file, rbkg1, e01, preEkws, kmin1, kmax1, kmin2, kmax2, kw2)\n",
    "                                                    for data_number, file in enumerate(filelist)]):\n",
    "            data_number, g = result\n",
    "            d[data_number] = g\n",
    "    else:\n",
    "        d = []\n",
    "        for file in filelist:\n",
    "            g = io.read_ascii(file, labels=['e', 'xmu'])\n",
    "            xafs.autobk(g.e, g.xmu, rbkg=rbkg1, e0=e01,\n",
    "                        pre_edge_kws=preEkws, kmin=kmin1, kmax=kmax1, group=g)\n",
    "            xafs.xftf(g, kmin=kmin2, kmax=kmax2, window='hanning',\n",
    "                      dk=1, kweight=kw2, group=g)\n",
    "            d.append(g)\n",
    "    if BENCH == True:\n",
    "        end_time_xafsana = time.perf_counter()  # for benchmark on 2202.10.25\n",
    "        differential_time_xafsana = end_time_xafsana - \\\n",
    "            start_time_xafsana  # for benchmark on 2202.10.25\n",
    "        with open(\"bench.txt\", mode=\"a+\") as bench_file:  # for benchmark on 2202.10.25\n",
    "            # for benchmark on 2202.10.25\n",
    "            bench_file.write(\n",
    "                f\"XAFS_ana_all are called in {differential_time_xafsana}  on {datetime.datetime.now()} \\n\")\n",
    "    return d\n",
    "\n",
    "# XAFSanaのデータのフィッティング\n",
    "# modified by Fujikawa on 2022.Nov\n",
    "\n",
    "\n",
    "def FEFFfit(d, checkbox_multiprocess_fit_value, checkbox_optimize_fit_value, fit_cpu_core):\n",
    "    readfile, preE1, preE2, postE1, postE2, e01, normO, rbkg1, kmin1, kmax1, kmin2, kmax2, rmin1, rmax1, kw2 = read_arg2()\n",
    "    No_path, para_name, para_value, para_min, para_max, para_variable, feff_l, para2_u_l, para2_name, para2_value, para2_min, para2_max, para2_variable = read_arg3()\n",
    "    pars = param_group()\n",
    "    logger.debug(f'param group = {feff_l}\\n')\n",
    "    n = 0\n",
    "    para2_u = para2_u_l[0]*1+para2_u_l[1]*2+para2_u_l[2]*4\n",
    "    feff_path_list = []\n",
    "    if n < No_path:  # 1つめのpath\n",
    "        a1 = param(para_value[0][n], min=para_min[0][n],\n",
    "                   max=para_max[0][n], vary=para_variable[0][n])\n",
    "        e1 = param(para_value[1][n], min=para_min[1][n],\n",
    "                   max=para_max[1][n], vary=para_variable[1][n])\n",
    "        r1 = param(para_value[2][n], min=para_min[2][n],\n",
    "                   max=para_max[2][n], vary=para_variable[2][n])\n",
    "        s1 = param(para_value[3][n], min=para_min[3][n],\n",
    "                   max=para_max[3][n], vary=para_variable[3][n])\n",
    "        pars.a1 = a1\n",
    "        pars.e1 = e1\n",
    "        pars.r1 = r1\n",
    "        pars.s1 = s1\n",
    "        if para2_u_l[0]:\n",
    "            c31 = param(para2_value[0][n], min=para2_min[0][n],\n",
    "                        max=para2_max[0][n], vary=para2_variable[0][n])\n",
    "            pars.c31 = c31\n",
    "        if para2_u_l[1]:\n",
    "            c41 = param(para2_value[1][n], min=para2_min[1][n],\n",
    "                        max=para2_max[1][n], vary=para2_variable[1][n])\n",
    "            pars.c41 = c41\n",
    "        if para2_u_l[2]:\n",
    "            ei1 = param(para2_value[2][n], min=para2_min[2][n],\n",
    "                        max=para2_max[2][n], vary=para2_variable[2][n])\n",
    "            pars.ei1 = ei1\n",
    "        if para2_u == 0:\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', _larch=session))\n",
    "        elif para2_u == 1:  # C3\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', third='c31', _larch=session))\n",
    "        elif para2_u == 2:  # C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', fourth='c41', _larch=session))\n",
    "        elif para2_u == 3:  # C3,C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', third='c31', fourth='c41', _larch=session))\n",
    "        elif para2_u == 4:  # Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', ei='ei1', _larch=session))\n",
    "        elif para2_u == 5:  # C3,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', third='c31', ei='ei1', _larch=session))\n",
    "        elif para2_u == 6:  # C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', fourth='c41', ei='ei1', _larch=session))\n",
    "        elif para2_u == 7:  # C3,C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a1', e0='e1', deltar='r1', sigma2='s1', third='c31', fourth='c41', ei='ei1', _larch=session))\n",
    "        n = n+1\n",
    "    if n < No_path:  # 2つ目のpath\n",
    "        a2 = param(para_value[0][n], min=para_min[0][n],\n",
    "                   max=para_max[0][n], vary=para_variable[0][n])\n",
    "        e2 = param(para_value[1][n], min=para_min[1][n],\n",
    "                   max=para_max[1][n], vary=para_variable[1][n])\n",
    "        r2 = param(para_value[2][n], min=para_min[2][n],\n",
    "                   max=para_max[2][n], vary=para_variable[2][n])\n",
    "        s2 = param(para_value[3][n], min=para_min[3][n],\n",
    "                   max=para_max[3][n], vary=para_variable[3][n])\n",
    "        pars.a2 = a2\n",
    "        pars.e2 = e2\n",
    "        pars.r2 = r2\n",
    "        pars.s2 = s2\n",
    "        if para2_u_l[0]:\n",
    "            c32 = param(para2_value[0][n], min=para2_min[0][n],\n",
    "                        max=para2_max[0][n], vary=para2_variable[0][n])\n",
    "            pars.c32 = c32\n",
    "        if para2_u_l[1]:\n",
    "            c42 = param(para2_value[1][n], min=para2_min[1][n],\n",
    "                        max=para2_max[1][n], vary=para2_variable[1][n])\n",
    "            pars.c42 = c42\n",
    "        if para2_u_l[2]:\n",
    "            ei2 = param(para2_value[2][n], min=para2_min[2][n],\n",
    "                        max=para2_max[2][n], vary=para2_variable[2][n])\n",
    "            pars.ei2 = ei2\n",
    "        if para2_u == 0:\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', _larch=session))\n",
    "        elif para2_u == 1:  # C3\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', third='c32', _larch=session))\n",
    "        elif para2_u == 2:  # C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', fourth='c42', _larch=session))\n",
    "        elif para2_u == 3:  # C3,C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', third='c32', fourth='c42', _larch=session))\n",
    "        elif para2_u == 4:  # Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', ei='ei2', _larch=session))\n",
    "        elif para2_u == 5:  # C3,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', third='c32', ei='ei2', _larch=session))\n",
    "        elif para2_u == 6:  # C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', fourth='c42', ei='ei2', _larch=session))\n",
    "        elif para2_u == 7:  # C3,C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a2', e0='e2', deltar='r2', sigma2='s2', third='c32', fourth='c42', ei='ei2', _larch=session))\n",
    "        n = n+1\n",
    "    if n < No_path:  # 3つ目のpath\n",
    "        a3 = param(para_value[0][n], min=para_min[0][n],\n",
    "                   max=para_max[0][n], vary=para_variable[0][n])\n",
    "        e3 = param(para_value[1][n], min=para_min[1][n],\n",
    "                   max=para_max[1][n], vary=para_variable[1][n])\n",
    "        r3 = param(para_value[2][n], min=para_min[2][n],\n",
    "                   max=para_max[2][n], vary=para_variable[2][n])\n",
    "        s3 = param(para_value[3][n], min=para_min[3][n],\n",
    "                   max=para_max[3][n], vary=para_variable[3][n])\n",
    "        pars.a3 = a3\n",
    "        pars.e3 = e3\n",
    "        pars.r3 = r3\n",
    "        pars.s3 = s3\n",
    "        if para2_u_l[0]:\n",
    "            c33 = param(para2_value[0][n], min=para2_min[0][n],\n",
    "                        max=para2_max[0][n], vary=para2_variable[0][n])\n",
    "            pars.c33 = c33\n",
    "        if para2_u_l[1]:\n",
    "            c43 = param(para2_value[1][n], min=para2_min[1][n],\n",
    "                        max=para2_max[1][n], vary=para2_variable[1][n])\n",
    "            pars.c43 = c43\n",
    "        if para2_u_l[2]:\n",
    "            ei3 = param(para2_value[2][n], min=para2_min[2][n],\n",
    "                        max=para2_max[2][n], vary=para2_variable[2][n])\n",
    "            pars.ei3 = ei3\n",
    "        if para2_u == 0:\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', _larch=session))\n",
    "        elif para2_u == 1:  # C3\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', third='c33', _larch=session))\n",
    "        elif para2_u == 2:  # C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', fourth='c43', _larch=session))\n",
    "        elif para2_u == 3:  # C3,C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', third='c33', fourth='c43', _larch=session))\n",
    "        elif para2_u == 4:  # Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', ei='ei3', _larch=session))\n",
    "        elif para2_u == 5:  # C3,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', third='c33', ei='ei3', _larch=session))\n",
    "        elif para2_u == 6:  # C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', fourth='c43', ei='ei3', _larch=session))\n",
    "        elif para2_u == 7:  # C3,C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a3', e0='e3', deltar='r3', sigma2='s3', third='c33', fourth='c43', ei='ei3', _larch=session))\n",
    "        n = n+1\n",
    "    if n < No_path:  # 4つ目のpath\n",
    "        a4 = param(para_value[0][n], min=para_min[0][n],\n",
    "                   max=para_max[0][n], vary=para_variable[0][n])\n",
    "        e4 = param(para_value[1][n], min=para_min[1][n],\n",
    "                   max=para_max[1][n], vary=para_variable[1][n])\n",
    "        r4 = param(para_value[2][n], min=para_min[2][n],\n",
    "                   max=para_max[2][n], vary=para_variable[2][n])\n",
    "        s4 = param(para_value[3][n], min=para_min[3][n],\n",
    "                   max=para_max[3][n], vary=para_variable[3][n])\n",
    "        pars.a4 = a4\n",
    "        pars.e4 = e4\n",
    "        pars.r4 = r4\n",
    "        pars.s4 = s4\n",
    "        if para2_u_l[0]:\n",
    "            c34 = param(para2_value[0][n], min=para2_min[0][n],\n",
    "                        max=para2_max[0][n], vary=para2_variable[0][n])\n",
    "            pars.c34 = c34\n",
    "        if para2_u_l[1]:\n",
    "            c44 = param(para2_value[1][n], min=para2_min[1][n],\n",
    "                        max=para2_max[1][n], vary=para2_variable[1][n])\n",
    "            pars.c44 = c44\n",
    "        if para2_u_l[2]:\n",
    "            ei4 = param(para2_value[2][n], min=para2_min[2][n],\n",
    "                        max=para2_max[2][n], vary=para2_variable[2][n])\n",
    "            pars.ei4 = ei4\n",
    "        if para2_u == 0:\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', _larch=session))\n",
    "        elif para2_u == 1:  # C3\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', third='c34', _larch=session))\n",
    "        elif para2_u == 2:  # C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', fourth='c44', _larch=session))\n",
    "        elif para2_u == 3:  # C3,C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', third='c34', fourth='c44', _larch=session))\n",
    "        elif para2_u == 4:  # Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', ei='ei4', _larch=session))\n",
    "        elif para2_u == 5:  # C3,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', third='c34', ei='ei4', _larch=session))\n",
    "        elif para2_u == 6:  # C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', fourth='c44', ei='ei4', _larch=session))\n",
    "        elif para2_u == 7:  # C3,C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a4', e0='e4', deltar='r4', sigma2='s4', third='c34', fourth='c44', ei='ei4', _larch=session))\n",
    "        n = n+1\n",
    "    if n < No_path:  # 5つ目のpath\n",
    "        a5 = param(para_value[0][n], min=para_min[0][n],\n",
    "                   max=para_max[0][n], vary=para_variable[0][n])\n",
    "        e5 = param(para_value[1][n], min=para_min[1][n],\n",
    "                   max=para_max[1][n], vary=para_variable[1][n])\n",
    "        r5 = param(para_value[2][n], min=para_min[2][n],\n",
    "                   max=para_max[2][n], vary=para_variable[2][n])\n",
    "        s5 = param(para_value[3][n], min=para_min[3][n],\n",
    "                   max=para_max[3][n], vary=para_variable[3][n])\n",
    "        pars.a5 = a5\n",
    "        pars.e5 = e5\n",
    "        pars.r5 = r5\n",
    "        pars.s5 = s5\n",
    "        if para2_u_l[0]:\n",
    "            c35 = param(para2_value[0][n], min=para2_min[0][n],\n",
    "                        max=para2_max[0][n], vary=para2_variable[0][n])\n",
    "            pars.c35 = c35\n",
    "        if para2_u_l[1]:\n",
    "            c45 = param(para2_value[1][n], min=para2_min[1][n],\n",
    "                        max=para2_max[1][n], vary=para2_variable[1][n])\n",
    "            pars.c45 = c45\n",
    "        if para2_u_l[2]:\n",
    "            ei5 = param(para2_value[2][n], min=para2_min[2][n],\n",
    "                        max=para2_max[2][n], vary=para2_variable[2][n])\n",
    "            pars.ei5 = ei5\n",
    "        if para2_u == 0:\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', _larch=session))\n",
    "        elif para2_u == 1:  # C3\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', third='c35', _larch=session))\n",
    "        elif para2_u == 2:  # C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', fourth='c45', _larch=session))\n",
    "        elif para2_u == 3:  # C3,C4\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', third='c35', fourth='c45', _larch=session))\n",
    "        elif para2_u == 4:  # Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', ei='ei5', _larch=session))\n",
    "        elif para2_u == 5:  # C3,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', third='c35', ei='ei5', _larch=session))\n",
    "        elif para2_u == 6:  # C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', fourth='c45', ei='ei5', _larch=session))\n",
    "        elif para2_u == 7:  # C3,C4,Ei\n",
    "            feff_path_list.append(xafs.feffpath(\n",
    "                feff_l[n], s02='a5', e0='e5', deltar='r5', sigma2='s5', third='c35', fourth='c45', ei='ei5', _larch=session))\n",
    "    trans = xafs.feffit_transform(fitspace='r', kmin=kmin2, kmax=kmax2,\n",
    "                                  dk=1, kweight=kw2, rmin=rmin1, rmax=rmax1, window='hanning')\n",
    "    # outの中から必要なパラメータを出力する。欲しい値は同じidのオブジェクトなので書き換えられてしまうため。\n",
    "    out_l = ny.zeros((No_path, len(d), 15))\n",
    "\n",
    "    if checkbox_multiprocess_fit_value is True:\n",
    "        logger.info('thread and optimize fit was ON')\n",
    "        g2 = [0 for _ in range(len(d))]\n",
    "        dataset_l = [0 for _ in range(len(d))]\n",
    "\n",
    "        # processに渡すためdをコア数で分割したリストを作成\n",
    "        splited_d_list = ny.array_split(d, fit_cpu_core)\n",
    "        # splited_d_listのファイルの初期インデックスリストの作成\n",
    "        ini = 0\n",
    "        initial_d_indices = []\n",
    "        for splited_ds in splited_d_list:\n",
    "            initial_d_indices.append(ini)\n",
    "            ini += len(splited_ds)\n",
    "        logger.debug(f'initial index list = {initial_d_indices}')\n",
    "        logger.debug(\n",
    "            f'length splited_d_list, initial_d_indices = {len(splited_d_list)}, {len(initial_d_indices)}')\n",
    "\n",
    "        # 各プロセスの初めのデータのみ変数の初期化を行う\n",
    "        flag_initialize_all = False\n",
    "        # joblibによるマルチプロセス\n",
    "        for results in Parallel(n_jobs=fit_cpu_core)([delayed(process_calc_fefffit)(initial_d_index, d_list, flag_initialize_all, checkbox_optimize_fit_value, feff_path_list, trans, pars, para_min, para_max,\n",
    "                                                                                    para_variable, n,  No_path)\n",
    "                                                      for initial_d_index, d_list in zip(initial_d_indices, splited_d_list)]):\n",
    "\n",
    "            for data_number in results.keys():\n",
    "                g2[data_number] = results[data_number][0]\n",
    "                dataset_l[data_number] = results[data_number][1]\n",
    "                out_l[:, data_number, :] = results[data_number][2]\n",
    "\n",
    "    else:\n",
    "        logger.info('Normal fit was ON ')\n",
    "        g2 = [0 for _ in range(len(d))]\n",
    "        dataset_l = [0 for _ in range(len(d))]\n",
    "        flag_opt = True\n",
    "        _thread_calc_fefffit(0, d[0], g2, out_l, dataset_l, flag_opt, checkbox_optimize_fit_value,\n",
    "                             feff_path_list, trans, session, pars, para_min, para_max, para_variable, n, No_path)\n",
    "        flag_opt = False\n",
    "        for i, group in enumerate(d[1:]):\n",
    "            _thread_calc_fefffit(i+1, group, g2, out_l, dataset_l, flag_opt, checkbox_optimize_fit_value,\n",
    "                                 feff_path_list, trans, session, pars, para_min, para_max, para_variable, n, No_path)\n",
    "\n",
    "    return g2, out_l, dataset_l\n",
    "\n",
    "# @jit\n",
    "\n",
    "\n",
    "def _optimize_fit_variables(fitout, pars, para_min, para_max, para_variable, n):\n",
    "    \"\"\" \n",
    "        reassignment variable values of last fitting results to pars\n",
    "    \"\"\"\n",
    "    pars.a1 = param(fitout.params['a1'].value, min=para_min[0]\n",
    "                    [n], max=para_max[0][n], vary=para_variable[0][n])\n",
    "    pars.e1 = param(fitout.params['e1'].value, min=para_min[1]\n",
    "                    [n], max=para_max[1][n], vary=para_variable[1][n])\n",
    "    pars.r1 = param(fitout.params['r1'].value, min=para_min[2]\n",
    "                    [n], max=para_max[2][n], vary=para_variable[2][n])\n",
    "    pars.s1 = param(fitout.params['s1'].value, min=para_min[3]\n",
    "                    [n], max=para_max[3][n], vary=para_variable[3][n])\n",
    "\n",
    "\n",
    "def _thread_calc_fefffit(data_number, d, g2, out_l, dataset_l, flag_opt, checkbox_optimize_fit_value, feff_path_list, trans, session, pars, para_min, para_max, para_variable, n, No_path):\n",
    "\n",
    "    dset = xafs.feffit_dataset(\n",
    "        data=d, pathlist=feff_path_list, transform=trans, _larch=session)\n",
    "    fitout = xafs.feffit(pars, dset, _larch=session)\n",
    "    if checkbox_optimize_fit_value is True:\n",
    "        if flag_opt is True:\n",
    "            _optimize_fit_variables(\n",
    "                fitout, pars, para_min, para_max, para_variable, n)\n",
    "    g2[data_number] = d\n",
    "    # out_l[pathlist][datalist][paramlist]の3次元配列out_l[:,i,8]はR-factor(同じ値)\n",
    "    for np in range(No_path):\n",
    "        ll = feff_path_list[np].label\n",
    "        _assgin_results_out_l(np, data_number, out_l, fitout, ll)\n",
    "\n",
    "        dataset_l[data_number] = dset\n",
    "\n",
    "    return data_number\n",
    "\n",
    "\n",
    "def _assgin_results_out_l(np, data_number, out_l, fitout, ll):\n",
    "    par = fitout.params\n",
    "    out_l[np][data_number][0] = par.get('s02_'+ll).value\n",
    "    out_l[np][data_number][1] = par.get('e0_'+ll).value\n",
    "    out_l[np][data_number][2] = par.get('deltar_'+ll).value\n",
    "    out_l[np][data_number][3] = par.get('sigma2_'+ll).value\n",
    "    out_l[np][data_number][4] = par.get('s02_'+ll).stderr\n",
    "    out_l[np][data_number][5] = par.get('e0_'+ll).stderr\n",
    "    out_l[np][data_number][6] = par.get('deltar_'+ll).stderr\n",
    "    out_l[np][data_number][7] = par.get('sigma2_'+ll).stderr\n",
    "    out_l[np][data_number][8] = fitout.rfactor\n",
    "    out_l[np][data_number][9] = par.get('third_'+ll).value\n",
    "    out_l[np][data_number][10] = par.get('fourth_'+ll).value\n",
    "    out_l[np][data_number][11] = par.get('ei_'+ll).value\n",
    "    out_l[np][data_number][12] = par.get('third_'+ll).stderr\n",
    "    out_l[np][data_number][13] = par.get('fourth_'+ll).stderr\n",
    "    # xmu,chik,FT,fittingのグラフ描画class plot_bkgchift:\n",
    "    out_l[np][data_number][14] = par.get('ei_'+ll).stderr\n",
    "\n",
    "\n",
    "# xmu,chik,FT,fittingのグラフ描画\n",
    "\n",
    "class plot_bkgchift:\n",
    "    def __init__(self):\n",
    "        self.fig = plt.figure()\n",
    "\n",
    "        def plotter(select):\n",
    "            if select == 'xmu':  # xmu選択時、色々表示選択チェックボックス作る\n",
    "                def plotxmu(Norm, Pre_edge_line, Post_edge_line, Background, Emin, Emax):\n",
    "                    self.fig.clear()\n",
    "\n",
    "                    d = XAFSana(2)\n",
    "                    for g in d:\n",
    "                        if Norm:  # NormにチェックついているときはNormのみ描画\n",
    "                            plt.plot(g.e, g.flat, color='b')\n",
    "                        else:\n",
    "                            if Pre_edge_line:\n",
    "                                plt.plot(g.e, g.pre_edge, color='g')\n",
    "                            if Post_edge_line:\n",
    "                                plt.plot(g.e, g.post_edge, color='m')\n",
    "                            if Background:\n",
    "                                plt.plot(g.e, g.bkg, color='r')\n",
    "                            plt.plot(g.e, g.xmu, color='b')\n",
    "                    plt.xlim(g.e0+Emin, g.e0+Emax)  # グラフ描画範囲\n",
    "                C1 = Checkbox(value=True, description='Pre edge line')\n",
    "                C2 = Checkbox(value=True, description='Post edge line')\n",
    "                C3 = Checkbox(value=True, description='Background')\n",
    "                C4 = Checkbox(value=False, description='Normalization')\n",
    "                F1 = BoundedFloatText(\n",
    "                    value=-200, min=-5000, max=5000, description='Emin')\n",
    "                F2 = BoundedFloatText(\n",
    "                    value=800, min=-5000, max=5000, description='Emax')\n",
    "                out = interactive_output(plotxmu, {\n",
    "                                         'Pre_edge_line': C1, 'Post_edge_line': C2, 'Background': C3, 'Norm': C4, 'Emin': F1, 'Emax': F2})\n",
    "                h1 = HBox([F1, F2])  # レイアウトをいじるのでinteractive_outputとdisplayを使う\n",
    "                ui = VBox([C1, C2, C3, C4, h1])\n",
    "                display(ui, out)\n",
    "            elif select == 'chik':  # スライダーで選択したkweighatのchik表示\n",
    "                def plotchi(kw, KMIN, KMAX):\n",
    "                    self.fig.clear()\n",
    "                    d = XAFSana(2)\n",
    "                    for g in d:\n",
    "                        plt.plot(g.k, g.chi*(g.k**kw), color='b')\n",
    "                    plt.xlim(KMIN, KMAX)\n",
    "                S1 = IntSlider(value=2, min=0, max=3, step=1,\n",
    "                               description='plotting k-weight')\n",
    "                F1 = BoundedFloatText(\n",
    "                    value=0, min=0, max=20, description='kmin')\n",
    "                F2 = BoundedFloatText(\n",
    "                    value=15, min=0, max=20, description='kmax')\n",
    "                h1 = HBox([F1, F2])\n",
    "                ui = VBox([S1, h1])\n",
    "                out = interactive_output(\n",
    "                    plotchi, {'kw': S1, 'KMIN': F1, 'KMAX': F2})\n",
    "                display(ui, out)\n",
    "            elif select == 'FT':\n",
    "                def plotFT(Magnitude, Real_part, Imag_part, Rmin, Rmax, pkw):\n",
    "                    self.fig.clear()\n",
    "                    d = XAFSana(pkw)\n",
    "                    for g in d:\n",
    "                        if Magnitude:\n",
    "                            plt.plot(g.r, g.chir_mag, color='b')\n",
    "                        if Real_part:\n",
    "                            plt.plot(g.r, g.chir_re, color='g')\n",
    "                        if Imag_part:\n",
    "                            plt.plot(g.r, g.chir_im, color='m')\n",
    "                    plt.xlim(Rmin, Rmax)\n",
    "                C1 = Checkbox(value=True, description='Magnitude')\n",
    "                C2 = Checkbox(value=False, description='Real part')\n",
    "                C3 = Checkbox(value=False, description='Imag. part')\n",
    "                F1 = BoundedFloatText(\n",
    "                    value=0, min=0, max=20, description='Rmin')\n",
    "                F2 = BoundedFloatText(\n",
    "                    value=6, min=0, max=20, description='Rmax')\n",
    "                S1 = IntSlider(value=2, min=0, max=3, step=1,\n",
    "                               description='plotting k-weight')\n",
    "                out = interactive_output(plotFT, {\n",
    "                                         'Magnitude': C1, 'Real_part': C2, 'Imag_part': C3, 'Rmin': F1, 'Rmax': F2, 'pkw': S1})\n",
    "                h1 = HBox([F1, F2])\n",
    "                ui = VBox([S1, C1, C2, C3, h1])\n",
    "                display(ui, out)\n",
    "            elif select == 'Fitting':\n",
    "                def plotfit(Rmin, Rmax):\n",
    "                    self.fig.clear()\n",
    "                    d = XAFSana(-1)\n",
    "                    # d2,d_out,d_dset=FEFFfit(d, checkbox_multiprocess_fit.value, checkbox_optimize_fit.value, inttext_thread_core.value)\n",
    "                    # TODO:checkbox_multiprocess_fit.value, checkbox_optimize_fit.value, inttext_thread_core.valueが定義前なので初期値を代入している\n",
    "                    d2, d_out, d_dset = FEFFfit(d, False, False, 1)\n",
    "                    filenamelist = read_arg1()[1]\n",
    "                    No_path = read_arg3()[0]\n",
    "                    txt_out = ''\n",
    "                    for g, dset in itertools.product(d2, d_dset):\n",
    "                        plt.plot(g.r, g.chir_mag)\n",
    "                        plt.plot(dset.model.r, dset.model.chir_mag)\n",
    "                    plt.xlim(Rmin, Rmax)\n",
    "                    for i in range(len(d2)):\n",
    "                        txt_out = txt_out + \\\n",
    "                            filenamelist[i] + ' R-factor=' + \\\n",
    "                            format(d_out[0, i, 8]*100, '.2f') + '\\n'\n",
    "                        for j in range(No_path):\n",
    "                            txt_out = (txt_out + 'Path' + str(j)\n",
    "                                       + ':S02=' +\n",
    "                                       format(d_out[j, i, 0], '.2f') +\n",
    "                                       '+- ' + format(d_out[j, i, 4], '.2f')\n",
    "                                       + ':E0=' +\n",
    "                                       format(d_out[j, i, 1], '.2f') +\n",
    "                                       '+- ' + format(d_out[j, i, 5], '.2f')\n",
    "                                       + ':deltar=' +\n",
    "                                       format(d_out[j, i, 2], '.2f') +\n",
    "                                       '+- ' + format(d_out[j, i, 6], '.2f')\n",
    "                                       + ':sigma2=' +\n",
    "                                       format(d_out[j, i, 3], '.2f') +\n",
    "                                       '+- ' + format(d_out[j, i, 7], '.2f')\n",
    "                                       + ':third=' +\n",
    "                                       format(d_out[j, i, 9], '.2f') +\n",
    "                                       '+- ' + format(d_out[j, i, 12], '.2f')\n",
    "                                       + ':fourth=' +\n",
    "                                       format(d_out[j, i, 10], '.2f') +\n",
    "                                       '+- ' + format(d_out[j, i, 13], '.2f')\n",
    "                                       + ':ei=' +\n",
    "                                       format(d_out[j, i, 11], '.2f') +\n",
    "                                       '+- ' + format(d_out[j, i, 14], '.2f')\n",
    "                                       + '\\n'\n",
    "                                       )\n",
    "                    T.value = txt_out\n",
    "                F1 = BoundedFloatText(\n",
    "                    value=0, min=0, max=10, description='Rmin')\n",
    "                F2 = BoundedFloatText(\n",
    "                    value=6, min=0, max=10, description='Rmax')\n",
    "                T = Textarea(value='fitting results', description='fitting results', layout=Layout(\n",
    "                    width='500px', height='200px'))\n",
    "                h1 = HBox([F1, F2])\n",
    "                ui = VBox([h1, T])\n",
    "                out = interactive_output(plotfit, {'Rmin': F1, 'Rmax': F2})\n",
    "                display(ui, out)\n",
    "        # xmu,chik,FTのdropdown生成\n",
    "        # HBoxとかでレイアウトをイジる必要がなければinteractのみで済む#読み込むファイルと保存先の設定class dataDset:\n",
    "        interact(plotter, select=['xmu', 'chik', 'FT', 'Fitting'])\n",
    "# 読み込むファイルと保存先の設定\n",
    "\n",
    "\n",
    "class dataDset:\n",
    "    def __init__(self, fileD, fileP, fileE, savefileD):\n",
    "        def savefilepara(fileD, fileP, fileE, savefileD):\n",
    "            with open('arg1.csv', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([fileD, fileP, fileE, savefileD])\n",
    "        T1 = Text(value=fileD, description='')\n",
    "        T2 = Text(value=fileP, description='', layout=Layout(width='100px'))\n",
    "        T3 = Text(value=fileE, description='', layout=Layout(width='100px'))\n",
    "        T4 = Text(value=savefileD, description='')\n",
    "        L1 = Label(value='data directory')\n",
    "        L2 = Label(value='data filename pattern')\n",
    "        L3 = Label(value='data filename extension')\n",
    "        L4 = Label(value='save directory')\n",
    "        out = interactive_output(\n",
    "            savefilepara, {'fileD': T1, 'fileP': T2, 'fileE': T3, 'savefileD': T4})\n",
    "        h1 = HBox([L1, T1, L2, T2, L3, T3])\n",
    "        h2 = HBox([L4, T4])\n",
    "        ui = VBox([h1, h2])\n",
    "        display(ui, out)\n",
    "# パラメーターを決める\n",
    "\n",
    "\n",
    "class Paramset:\n",
    "    def __init__(self):\n",
    "        filelist, filenamelist, savefileD = read_arg1()\n",
    "        global F_initial\n",
    "        ipreE1 = -200  # pre-edge line range\n",
    "        ipreE2 = -50\n",
    "        ipostE1 = 150  # post-edge line range\n",
    "        ipostE2 = 400\n",
    "        inormO = 3  # normalization order\n",
    "        irbkg1 = 1.0  # Rbkg\n",
    "        ikmin1 = 0.0  # spline range in k\n",
    "        ikmax1 = 15.0\n",
    "        ikmin2 = 3.0  # FT range in k\n",
    "        ikmax2 = 9.0\n",
    "        irmin1 = 1.0  # Fitting range in r\n",
    "        irmax1 = 3.0\n",
    "        ikw = 2  # Fitting k-weight\n",
    "        g = io.read_ascii(filelist[0], labels=['e', 'xmu'])\n",
    "        ee0 = xafs.find_e0(g.e, g.xmu)\n",
    "        if os.path.isfile('arg2.csv') == True:  # arg2.csvが存在し、同じ吸収端であれば初期値とする。\n",
    "            i2readfile, i2preE1, i2preE2, i2postE1, i2postE2, i2e01, i2normO, i2rbkg1, i2kmin1, i2kmax1, i2kmin2, i2kmax2, i2rmin1, i2rmax1, i2kw = read_arg2()\n",
    "            if xray.guess_edge(ee0) == xray.guess_edge(i2e01):\n",
    "                ipreE1, ipreE2, ipostE1, ipostE2, inormO, irbkg1, ikmin1, ikmax1, ikmin2, ikmax2, irmin1, irmax1,\\\n",
    "                    ikw = i2preE1, i2preE2, i2postE1, i2postE2, i2normO, i2rbkg1, i2kmin1, i2kmax1, i2kmin2, i2kmax2, i2rmin1, i2rmax1, i2kw\n",
    "                F_initial = True\n",
    "            else:\n",
    "                F_initial = False\n",
    "        else:\n",
    "            F_initial = False\n",
    "\n",
    "        def saveparam(preE1, preE2, postE1, postE2, e01, normO, rbkg1, kmin1, kmax1, kmin2, kmax2, readfilelist, rmin1, rmax1, kw2):\n",
    "            rfl1 = []\n",
    "            rf2 = ''\n",
    "            for rf1 in readfilelist:\n",
    "                rfl1.append(str(filenamelist.index(rf1)))\n",
    "            rf2 = ':'.join(rfl1)\n",
    "            with open('arg2.csv', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([rf2, preE1, preE2, postE1, postE2, e01, normO,\n",
    "                                rbkg1, kmin1, kmax1, kmin2, kmax2, rmin1, rmax1, kw2])\n",
    "        F2 = BoundedFloatText(value=ipreE1, min=-1000, max=0,\n",
    "                              description='', layout=Layout(width='100px'))  # preE1\n",
    "        F3 = BoundedFloatText(value=ipreE2, min=-1000, max=0,\n",
    "                              description='', layout=Layout(width='100px'))  # preE2\n",
    "        F4 = BoundedFloatText(value=ipostE1, min=0, max=1000,\n",
    "                              description='', layout=Layout(width='100px'))  # postE1\n",
    "        F5 = BoundedFloatText(value=ipostE2, min=0, max=1000,\n",
    "                              description='', layout=Layout(width='100px'))  # postE2\n",
    "        F6 = BoundedFloatText(value=ee0, min=-1, max=150000,\n",
    "                              description='', layout=Layout(width='100px'))  # e01\n",
    "        F7 = IntSlider(value=inormO, min=1, max=3, step=1,\n",
    "                       description='', layout=Layout(width='200px'))  # normO\n",
    "        F8 = BoundedFloatText(value=irbkg1, min=0, max=5,\n",
    "                              description='', layout=Layout(width='50px'))  # rbkg1\n",
    "        F9 = BoundedFloatText(value=ikmin1, min=0, max=20,\n",
    "                              description='', layout=Layout(width='100px'))  # kmin1\n",
    "        F10 = BoundedFloatText(value=ikmax1, min=0, max=20,\n",
    "                               description='', layout=Layout(width='100px'))  # kmax1\n",
    "        F11 = BoundedFloatText(value=ikmin2, min=0, max=20,\n",
    "                               description='', layout=Layout(width='100px'))  # kmin2\n",
    "        F12 = BoundedFloatText(value=ikmax2, min=0, max=20,\n",
    "                               description='', layout=Layout(width='100px'))  # kmax2\n",
    "        F13 = BoundedFloatText(value=irmin1, min=0, max=10,\n",
    "                               description='', layout=Layout(width='100px'))  # rmin1\n",
    "        F14 = BoundedFloatText(value=irmax1, min=0, max=10,\n",
    "                               description='', layout=Layout(width='100px'))  # rmax1\n",
    "        F15 = BoundedFloatText(\n",
    "            value=ikw, min=0, max=4, description='', layout=Layout(width='50px'))  # kw2\n",
    "        S1 = SelectMultiple(options=filenamelist, value=[\n",
    "                            filenamelist[0]], layout=Layout(height='200px'))\n",
    "        L2 = Label(value='Normalization order')\n",
    "        L3 = Label(value='Pre-edge range')\n",
    "        L4 = Label(value='Normalization range:')\n",
    "        L5 = Label(value='Spline range in k  :')\n",
    "        L6 = Label(value='FT k-range         :')\n",
    "        L7 = Label(value='to')\n",
    "        L8 = Label(value='E0')\n",
    "        L9 = Label(value='Rbkg')\n",
    "        L10 = Label(value='Fitting R-range')\n",
    "        L11 = Label(value='kw')\n",
    "        out = interactive_output(saveparam, {'preE1': F2, 'preE2': F3, 'postE1': F4, 'postE2': F5, 'e01': F6,\n",
    "                                             'normO': F7, 'rbkg1': F8, 'kmin1': F9, 'kmax1': F10, 'kmin2': F11, 'kmax2': F12,\n",
    "                                             'readfilelist': S1, 'rmin1': F13, 'rmax1': F14, 'kw2': F15})\n",
    "        h2 = HBox([L8, F6, L2, F7])\n",
    "        h3 = HBox([L3, F2, L7, F3])\n",
    "        h4 = HBox([L4, F4, L7, F5])\n",
    "        h5 = HBox([L9, F8])\n",
    "        h6 = HBox([L5, F9, L7, F10])\n",
    "        h7 = HBox([L6, F11, L7, F12])\n",
    "        h8 = HBox([L10, F13, L7, F14, L11, F15])\n",
    "        v1 = VBox([h2, h3, h4, h5, h6, h7, h8])\n",
    "        ui = HBox([v1, S1])\n",
    "        display(ui, out)\n",
    "\n",
    "# pathの設定\n",
    "\n",
    "\n",
    "class pathlist:\n",
    "    def __init__(self):\n",
    "        global F_initial\n",
    "        p_list = ['path1', 'path2', 'path3', 'path4', 'path5']\n",
    "        if os.path.isfile('arg3.csv') and F_initial:\n",
    "            No_path, para_name, para_value, para_min, para_max, para_variable, feff_l, para2_u_l, para2_name, para2_value, para2_min, para2_max, para2_variable = read_arg3()\n",
    "            a_n = para_name[0][:]\n",
    "            e_n = para_name[1][:]\n",
    "            r_n = para_name[2][:]\n",
    "            s_n = para_name[3][:]\n",
    "            c3_n = para2_name[0][:]\n",
    "            c4_n = para2_name[1][:]\n",
    "            ei_n = para2_name[2][:]\n",
    "            a_v, e_v, r_v, s_v, c3_v, c4_v, ei_v = para_value[0][:], para_value[1][:], para_value[\n",
    "                2][:], para_value[3][:], para2_value[0][:], para2_value[1][:], para2_value[2][:]\n",
    "            a_va, e_va, r_va, s_va, c3_va, c4_va, ei_va = para_variable[0][:], para_variable[1][:], para_variable[\n",
    "                2][:], para_variable[3][:], para2_variable[0][:], para2_variable[1][:], para2_variable[2][:]\n",
    "            a_min, e_min, r_min, s_min, c3_min, c4_min, ei_min = para_min[0][:], para_min[1][\n",
    "                :], para_min[2][:], para_min[3][:], para2_min[0][:], para2_min[1][:], para2_min[2][:]\n",
    "            a_max, e_max, r_max, s_max, c3_max, c4_max, ei_max = para_max[0][:], para_max[1][\n",
    "                :], para_max[2][:], para_max[3][:], para2_max[0][:], para2_max[1][:], para2_max[2][:]\n",
    "        else:\n",
    "            No_path = 1\n",
    "            a_n = ['amp1', 'amp2', 'amp3', 'amp4', 'amp5']\n",
    "            e_n = ['e01', 'e02', 'e03', 'e04', 'e05']\n",
    "            r_n = ['delr1', 'delr2', 'delr3', 'delr4', 'delr5']\n",
    "            s_n = ['ss1', 'ss2', 'ss3', 'ss4', 'ss5']\n",
    "            c3_n = ['C3_1', 'C3_2', 'C3_3', 'C3_4', 'C3_5']\n",
    "            c4_n = ['C4_1', 'C4_2', 'C4_3', 'C4_4', 'C4_5']\n",
    "            ei_n = ['Ei_1', 'Ei_2', 'Ei_3', 'Ei_4', 'Ei_5']\n",
    "            a_v, e_v, r_v, s_v, c3_v, c4_v, ei_v = [\n",
    "                1]*5, [0]*5, [0]*5, [0.003]*5, [0]*5, [0]*5, [0]*5\n",
    "            a_va, e_va, r_va, s_va, c3_va, c4_va, ei_va = [\n",
    "                True]*5, [True]*5, [True]*5, [True]*5, [True]*5, [True]*5, [True]*5\n",
    "            a_min, e_min, r_min, s_min, c3_min, c4_min, ei_min = [\n",
    "                0]*5, [-10]*5, [-2]*5, [0]*5, [-10]*5, [-10]*5, [-10]*5\n",
    "            a_max, e_max, r_max, s_max, c3_max, c4_max, ei_max = [\n",
    "                20]*5, [10]*5, [2]*5, [1]*5, [10]*5, [10]*5, [10]*5\n",
    "            feff_l = ['feff0001.dat']*5\n",
    "            para2_u_l = [False]*3\n",
    "        F_initial = False\n",
    "\n",
    "        def path_set(No_path, pathname, u_c3, u_c4, u_ei):\n",
    "            def path_param_set(a_value, e_value, r_value, s_value,\n",
    "                               a_minimum, e_minimum, r_minimum, s_minimum,\n",
    "                               a_maximum, e_maximum, r_maximum, s_maximum,\n",
    "                               a_variable, e_variable, r_variable, s_variable,\n",
    "                               a_name, e_name, r_name, s_name, feffdat_path,\n",
    "                               c3_value, c3_minimum, c3_maximum, c3_variable,\n",
    "                               c4_value, c4_minimum, c4_maximum, c4_variable,\n",
    "                               ei_value, ei_minimum, ei_maximum, ei_variable,\n",
    "                               c3_name, c4_name, ei_name):\n",
    "                a_n[p_index] = a_name\n",
    "                e_n[p_index] = e_name\n",
    "                r_n[p_index] = r_name\n",
    "                s_n[p_index] = s_name\n",
    "                a_v[p_index] = a_value\n",
    "                e_v[p_index] = e_value\n",
    "                r_v[p_index] = r_value\n",
    "                s_v[p_index] = s_value\n",
    "                a_min[p_index] = a_minimum\n",
    "                e_min[p_index] = e_minimum\n",
    "                r_min[p_index] = r_minimum\n",
    "                s_min[p_index] = s_minimum\n",
    "                a_max[p_index] = a_maximum\n",
    "                e_max[p_index] = e_maximum\n",
    "                r_max[p_index] = r_maximum\n",
    "                s_max[p_index] = s_maximum\n",
    "                a_va[p_index] = a_variable\n",
    "                e_va[p_index] = e_variable\n",
    "                r_va[p_index] = r_variable\n",
    "                s_va[p_index] = s_variable\n",
    "                feff_l[p_index] = feffdat_path\n",
    "                u_list = [u_c3, u_c4, u_ei]\n",
    "                if u_c3 == True:\n",
    "                    c3_n[p_index] = c3_name\n",
    "                    c3_v[p_index] = c3_value\n",
    "                    c3_min[p_index] = c3_minimum\n",
    "                    c3_max[p_index] = c3_maximum\n",
    "                    c3_va[p_index] = c3_variable\n",
    "                if u_c4 == True:\n",
    "                    c4_n[p_index] = c4_name\n",
    "                    c4_v[p_index] = c4_value\n",
    "                    c4_min[p_index] = c4_minimum\n",
    "                    c4_max[p_index] = c4_maximum\n",
    "                    c4_va[p_index] = c4_variable\n",
    "                if u_ei == True:\n",
    "                    ei_n[p_index] = ei_name\n",
    "                    ei_v[p_index] = ei_value\n",
    "                    ei_min[p_index] = ei_minimum\n",
    "                    ei_max[p_index] = ei_maximum\n",
    "                    ei_va[p_index] = ei_variable\n",
    "                with open('arg3.csv', 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([No_path])\n",
    "                    writer.writerow(a_n+e_n+r_n+s_n)\n",
    "                    writer.writerow(a_v+e_v+r_v+s_v)\n",
    "                    writer.writerow(a_min+e_min+r_min+s_min)\n",
    "                    writer.writerow(a_max+e_max+r_max+s_max)\n",
    "                    writer.writerow(a_va+e_va+r_va+s_va)\n",
    "                    writer.writerow(feff_l)\n",
    "                    writer.writerow(u_list)\n",
    "                    writer.writerow(c3_n+c4_n+ei_n)\n",
    "                    writer.writerow(c3_v+c4_v+ei_v)\n",
    "                    writer.writerow(c3_min+c4_min+ei_min)\n",
    "                    writer.writerow(c3_max+c4_max+ei_max)\n",
    "                    writer.writerow(c3_va+c4_va+ei_va)\n",
    "            p_index = p_list.index(pathname)\n",
    "            T1 = Text(value=a_n[p_index])  # 名前\n",
    "            T2 = Text(value=e_n[p_index])\n",
    "            T3 = Text(value=r_n[p_index])\n",
    "            T4 = Text(value=s_n[p_index])\n",
    "            F1 = BoundedFloatText(value=a_v[p_index], min=-100, max=100)  # 初期値\n",
    "            F2 = BoundedFloatText(value=e_v[p_index], min=-100, max=100)\n",
    "            F3 = BoundedFloatText(value=r_v[p_index], min=-100, max=100)\n",
    "            F4 = BoundedFloatText(value=s_v[p_index], min=-100, max=100)\n",
    "            F5 = BoundedFloatText(\n",
    "                value=a_min[p_index], min=-100, max=100)  # 下限値\n",
    "            F6 = BoundedFloatText(value=e_min[p_index], min=-100, max=100)\n",
    "            F7 = BoundedFloatText(value=r_min[p_index], min=-100, max=100)\n",
    "            F8 = BoundedFloatText(value=s_min[p_index], min=-100, max=100)\n",
    "            F9 = BoundedFloatText(\n",
    "                value=a_max[p_index], min=-100, max=100)  # 上限値\n",
    "            F10 = BoundedFloatText(value=e_max[p_index], min=-100, max=100)\n",
    "            F11 = BoundedFloatText(value=r_max[p_index], min=-100, max=100)\n",
    "            F12 = BoundedFloatText(value=s_max[p_index], min=-100, max=100)\n",
    "            C1 = Checkbox(value=a_va[p_index])  # フィッティングに使う変数？\n",
    "            C2 = Checkbox(value=e_va[p_index])\n",
    "            C3 = Checkbox(value=r_va[p_index])\n",
    "            C4 = Checkbox(value=s_va[p_index])\n",
    "            T5 = Text(value=feff_l[p_index])  # feffXXXX.datのパス\n",
    "            L1 = Text(value='Parameter name')\n",
    "            L2 = Text(value='Initial value')\n",
    "            L3 = Text(value='Minimum')\n",
    "            L4 = Text(value='Maximum')\n",
    "            L5 = Text(value='Variable?')\n",
    "            L6 = Label('feffXXXX.dat file path')\n",
    "            h1 = HBox([T1, F1, F5, F9, C1])\n",
    "            h2 = HBox([T2, F2, F6, F10, C2])\n",
    "            h3 = HBox([T3, F3, F7, F11, C3])\n",
    "            h4 = HBox([T4, F4, F8, F12, C4])\n",
    "            h5 = HBox([L1, L2, L3, L4, L5])\n",
    "            ui2_l = [h5, h1, h2, h3, h4]\n",
    "            T6 = Text(value=c3_n[p_index], disabled=not u_c3)\n",
    "            F13 = BoundedFloatText(\n",
    "                value=c3_v[p_index], min=-100, max=100, disabled=not u_c3)\n",
    "            F14 = BoundedFloatText(\n",
    "                value=c3_min[p_index], min=-100, max=100, disabled=not u_c3)\n",
    "            F15 = BoundedFloatText(\n",
    "                value=c3_max[p_index], min=-100, max=100, disabled=not u_c3)\n",
    "            C8 = Checkbox(value=c3_va[p_index], disabled=not u_c3)\n",
    "            h6 = HBox([T6, F13, F14, F15, C8])\n",
    "            ui2_l.append(h6)\n",
    "            T7 = Text(value=c4_n[p_index], disabled=not u_c4)\n",
    "            F16 = BoundedFloatText(\n",
    "                value=c4_v[p_index], min=-100, max=100, disabled=not u_c4)\n",
    "            F17 = BoundedFloatText(\n",
    "                value=c4_min[p_index], min=-100, max=100, disabled=not u_c4)\n",
    "            F18 = BoundedFloatText(\n",
    "                value=c4_max[p_index], min=-100, max=100, disabled=not u_c4)\n",
    "            C9 = Checkbox(value=c4_va[p_index], disabled=not u_c4)\n",
    "            h7 = HBox([T7, F16, F17, F18, C9])\n",
    "            ui2_l.append(h7)\n",
    "            T8 = Text(value=ei_n[p_index], disabled=not u_ei)\n",
    "            F19 = BoundedFloatText(\n",
    "                value=ei_v[p_index], min=-100, max=100, disabled=not u_ei)\n",
    "            F20 = BoundedFloatText(\n",
    "                value=ei_min[p_index], min=-100, max=100, disabled=not u_ei)\n",
    "            F21 = BoundedFloatText(\n",
    "                value=ei_max[p_index], min=-100, max=100, disabled=not u_ei)\n",
    "            C10 = Checkbox(value=ei_va[p_index], disabled=not u_ei)\n",
    "            h8 = HBox([T8, F19, F20, F21, C10])\n",
    "            ui2_l.append(h8)\n",
    "            h9 = HBox([L6, T5])\n",
    "            ui2_l.append(h9)\n",
    "            ui2 = VBox(ui2_l)\n",
    "            out2 = interactive_output(path_param_set, {'a_value': F1, 'e_value': F2, 'r_value': F3, 's_value': F4,\n",
    "                                                       'a_minimum': F5, 'e_minimum': F6, 'r_minimum': F7, 's_minimum': F8,\n",
    "                                                       'a_maximum': F9, 'e_maximum': F10, 'r_maximum': F11, 's_maximum': F12,\n",
    "                                                       'a_variable': C1, 'e_variable': C2, 'r_variable': C3, 's_variable': C4,\n",
    "                                                       'a_name': T1, 'e_name': T2, 'r_name': T3, 's_name': T4, 'feffdat_path': T5,\n",
    "                                                       'c3_value': F13, 'c3_minimum': F14, 'c3_maximum': F15, 'c3_variable': C8,\n",
    "                                                       'c4_value': F16, 'c4_minimum': F17, 'c4_maximum': F18, 'c4_variable': C9,\n",
    "                                                       'ei_value': F19, 'ei_minimum': F20, 'ei_maximum': F21, 'ei_variable': C10,\n",
    "                                                       'c3_name': T6, 'c4_name': T7, 'ei_name': T8})\n",
    "            display(ui2, out2)\n",
    "        I1 = BoundedIntText(value=No_path, min=1, max=5,\n",
    "                            description='No. of Paths')\n",
    "        D1 = Dropdown(value=p_list[0], options=p_list)\n",
    "        C5 = Checkbox(value=para2_u_l[0], description='C3')\n",
    "        C6 = Checkbox(value=para2_u_l[1], description='C4')\n",
    "        C7 = Checkbox(value=para2_u_l[2], description='Ei')\n",
    "        ui = HBox([I1, D1, C5, C6, C7])\n",
    "        out = interactive_output(\n",
    "            path_set, {'No_path': I1, 'pathname': D1, 'u_c3': C5, 'u_c4': C6, 'u_ei': C7})\n",
    "        display(ui, out)\n",
    "        # for threading of saving result files with numpy.savetxt() added by Fujikawa on 2022.11.15\n",
    "\n",
    "\n",
    "def _thread_savetxt(file_path, np_array, header_text):\n",
    "    ny.savetxt(file_path, np_array, header=header_text, delimiter='\\t')\n",
    "\n",
    "# リストにある全データの解析\n",
    "# modified by Fujikawa on 2022.Nov\n",
    "\n",
    "\n",
    "class fit_all:\n",
    "    def __init__(self):\n",
    "        def on_click_ana(clicked_button: Button) -> None:\n",
    "            logger.info(\n",
    "                f' fit_all logger start on {log_date.strftime(\"%Y%m%d%H%M%S\")}')\n",
    "            logger.info(f\"Initial setting values: MULTIPROCESS_FT={MULTIPROCESS_FT}, BINARY_SAVE={BINARY_SAVE}, THREAD_SAVE={THREAD_SAVE}, OPTIMIZE_FIT={OPTIMIZE_FIT}, MULTIPROCESS_FIT={MULTIPROCESS_FIT},  MEMORY_ASSESSEMENT={MEMORY_ASSESSMENT}, PROFILER={PROFILER}, BENCH={BENCH}, max_workers = {MULTIPROCESS_FIT_CPU_CORE}, max_workers of XAFSana_all = {MULTIPROCESS_FT_CPU_CORE}\")\n",
    "            logger.info(\n",
    "                f'Initial values:\\n  ipreE1={ipreE1}, ipreE2={ipreE2}, ipostE1={ipostE1}, ipostE2={ipostE2}, inormO={inormO}, irbkg1={irbkg1}, ikmin1={ikmin1}, ikmax1={ikmax1}, ikmin2={ikmin2}, ikmax2={ikmax2}, irmin1={irmin1}, irmax1={irmax1}, ikw={ikw}, F_initial={F_initial}')\n",
    "            logger.info(f'loger fit_all')\n",
    "            logger.info(f\"Setting values: MULTIPROCESS_FT={MULTIPROCESS_FT}, data save={selection_data_save.value}, OPTIMIZE_FIT={checkbox_optimize_fit.value}, \\nMULTIPROCESS_FIT={checkbox_multiprocess_fit.value}, FT CPU core = {inttext_thread_core_ft.value}, fit and save CPU core = {inttext_thread_core.value}, MEMORY_ASSESSEMENT={MEMORY_ASSESSMENT}, PROFILER={checkbox_profiler.value}, BENCH={BENCH}\")\n",
    "\n",
    "            if BENCH == True:\n",
    "                start_time = time.perf_counter()  # for benchmark on 2202.10.25\n",
    "                with open('bench.txt', mode='a+') as bench_file:  # for benchmark on 2202.10.25\n",
    "                    # for benchmark on 2202.10.25\n",
    "                    bench_file.write(\n",
    "                        f'on_click_ana on {datetime.datetime.now()} \\n')\n",
    "            if checkbox_profiler.value == True:\n",
    "                profiler_date = datetime.datetime.now()\n",
    "                fitall_profiler = cProfile.Profile()  # for profiler on 2202.10.26\n",
    "                fitall_profiler.enable()  # for profiler on 2202.10.26\n",
    "            filelist, filenamelist, savefileD = read_arg1()\n",
    "            savefileD = Path(savefileD)  # transfer str to Path strings\n",
    "            logger.info(f'Total number of files = {len(filelist)}')\n",
    "            if savefileD.is_dir() == False:\n",
    "                savefileD.mkdir()\n",
    "            save_args()\n",
    "            ft_cpu_core = inttext_thread_core_ft.value\n",
    "#            d=XAFSana_all()\n",
    "            d = XAFSana_all(ft_cpu_core)\n",
    "            if C1.value == True:\n",
    "                save_directory = savefileD / 'norm'\n",
    "                if BENCH == True:  # for benchmark on 2202.10.25\n",
    "                    start_time_c1 = time.perf_counter()\n",
    "                if save_directory.is_dir() == False:\n",
    "                    save_directory.mkdir()\n",
    "                HEADER_NORM = 'energy\\tnorm\\tmu\\tpre_edge\\tpost_edge\\tbkg'\n",
    "                if selection_data_save.value == 'TEXT':  # for threading on 2202.11.15\n",
    "                    with concurrent.futures.ThreadPoolExecutor(max_workers=inttext_thread_core.value) as executor:\n",
    "                        future_thread_savetxt = {executor.submit(_thread_savetxt, save_directory / f'norm_{fn}', ny.stack(\n",
    "                            [g.e, g.flat, g.xmu, g.pre_edge, g.post_edge, g.bkg], 1), HEADER_NORM): (g, fn) for g, fn in zip(d, filenamelist)}\n",
    "                elif selection_data_save.value == 'BINARY':  # for threading on 2202.11.15\n",
    "                    binarize_data = {}\n",
    "                    header_list = []\n",
    "                    for g, fn in zip(d, filenamelist):\n",
    "                        binarize_data[f'norm_{fn}'] = ny.stack(\n",
    "                            [g.e, g.flat, g.xmu, g.pre_edge, g.post_edge, g.bkg], 1)\n",
    "                        # 解凍処理の時に統一化するため少し無駄な処理\n",
    "                        header_list.append(HEADER_NORM)\n",
    "                    ny.savez(save_directory /\n",
    "                             f'norm_results.npz', **binarize_data)\n",
    "                    ny.save(save_directory / f'norm_header.npy', header_list)\n",
    "                else:\n",
    "                    for g, fn in zip(d, filenamelist):\n",
    "                        ny.savetxt(save_directory / f'norm_{fn}', ny.stack([g.e, g.flat, g.xmu, g.pre_edge, g.post_edge, g.bkg], 1),\n",
    "                                   header=HEADER_NORM, delimiter='\\t')\n",
    "                if BENCH == True:\n",
    "                    end_time = time.perf_counter()  # for benchmark on 2202.10.25\n",
    "                    differential_time = end_time - start_time\n",
    "                    differential_time_c1 = end_time - start_time_c1\n",
    "                    with open('bench.txt', mode='a+') as bench_file:\n",
    "                        bench_file.write(\n",
    "                            f'on_clic_ana and C1 are called in {differential_time}, {differential_time_c1}  on {datetime.datetime.now()} \\n')\n",
    "            if C2.value == True:\n",
    "                save_directory = savefileD / 'chik'\n",
    "                if BENCH == True:  # for benchmark on 2202.10.25\n",
    "                    start_time_c2 = time.perf_counter()\n",
    "                if save_directory.is_dir() == False:\n",
    "                    save_directory.mkdir()\n",
    "                if selection_data_save.value == 'TEXT':  # for threading on 2202.11.15\n",
    "                    with concurrent.futures.ThreadPoolExecutor(max_workers=inttext_thread_core.value) as executor:\n",
    "                        future_thread_savetxt = {executor.submit(_thread_savetxt, save_directory / f'chik_{fn}',\n",
    "                                                                 ny.stack([g.k, g.chi], 1), 'k\\tchi'): (g, fn) for g, fn in zip(d, filenamelist)}\n",
    "                elif selection_data_save.value == 'BINARY':  # for threading on 2202.11.15\n",
    "                    binarize_data = {}\n",
    "                    header_list = []\n",
    "                    for g, fn in zip(d, filenamelist):\n",
    "                        binarize_data[f'chik_{fn}'] = ny.stack([g.k, g.chi], 1)\n",
    "                        header_list.append('k\\tchi')\n",
    "                    ny.savez(save_directory /\n",
    "                             f'chik_results.npz', **binarize_data)\n",
    "                    ny.save(save_directory / f'chik_header.npy', header_list)\n",
    "                else:\n",
    "                    for g, fn in zip(d, filenamelist):\n",
    "                        ny.savetxt(save_directory / f'chik_{fn}', ny.stack(\n",
    "                            [g.k, g.chi], 1), header='k\\tchi', delimiter='\\t')\n",
    "                        # ny.savetxt(savefileD + '/chik/chik_'+fn, ny.stack([g.k,g.chi],1),header='k\\tchi',delimiter='\\t')\n",
    "                print('chik finished\\n')\n",
    "                if BENCH == True:  # for benchmark on 2202.10.25\n",
    "                    end_time = time.perf_counter()\n",
    "                    differential_time = end_time - start_time\n",
    "                    differential_time_c2 = end_time - start_time_c2\n",
    "                    with open('bench.txt', mode='a+') as bench_file:\n",
    "                        bench_file.write(\n",
    "                            f'on_clic_ana and C2 are called in {differential_time}, {differential_time_c2}  on {datetime.datetime.now()} \\n')\n",
    "            if C3.value == True:\n",
    "                save_directory = savefileD / 'FT'\n",
    "                if BENCH == True:\n",
    "                    start_time_c3 = time.perf_counter()  # for benchmark on 2202.10.25\n",
    "                if save_directory.is_dir() == False:\n",
    "                    save_directory.mkdir()\n",
    "#                if THREAD_SAVE == True: # for threading on 2202.11.15\n",
    "                if selection_data_save.value == 'TEXT':  # for threading on 2202.11.15\n",
    "                    with concurrent.futures.ThreadPoolExecutor(max_workers=inttext_thread_core.value) as executor:\n",
    "                        future_thread_savetxt = {executor.submit(_thread_savetxt, save_directory / f'FT_{fn}', ny.stack([g.r, g.chir_mag, g.chir_re, g.chir_im], 1),\n",
    "                                                                 f'FT k-weight={str(g.xftf_details.call_args.get(\"kweight\"))}\\nr\\tchir_mag\\tchir_re\\tchir_im'):\n",
    "                                                 (g, fn) for g, fn in zip(d, filenamelist)}\n",
    "#                elif BINARY_SAVE == True:  # for save files as binary files on 2202.11.17\n",
    "                elif selection_data_save.value == 'BINARY':  # for threading on 2202.11.15\n",
    "                    binarize_data = {}\n",
    "                    header_list = []\n",
    "                    for g, fn in zip(d, filenamelist):\n",
    "                        binarize_data[f'FT_{fn}'] = ny.stack(\n",
    "                            [g.r, g.chir_mag, g.chir_re, g.chir_im], 1)\n",
    "                        header_list.append(\n",
    "                            f'FT k-weight={str(g.xftf_details.call_args.get(\"kweight\"))}\\nr\\tchir_mag\\tchir_re\\tchir_im')\n",
    "                    ny.savez(save_directory /\n",
    "                             f'FT_results.npz', **binarize_data)\n",
    "                    ny.save(save_directory / f'FT_header.npy', header_list)\n",
    "                else:\n",
    "                    for g, fn in zip(d, filenamelist):\n",
    "                        ny.savetxt(save_directory / f'FT_{fn}',  ny.stack([g.r, g.chir_mag, g.chir_re, g.chir_im], 1),\n",
    "                                   header='FT k-weight='+str(g.xftf_details.call_args.get(\"kweight\"))+'\\nr\\tchir_mag\\tchir_re\\tchir_im', delimiter='\\t')\n",
    "                print('FT finished\\n')\n",
    "                if BENCH == True:  # for benchmark on 2202.10.25\n",
    "                    end_time = time.perf_counter()\n",
    "                    differential_time = end_time - start_time\n",
    "                    differential_time_c3 = end_time - start_time_c3\n",
    "                    with open('bench.txt', mode='a+') as bench_file:\n",
    "                        bench_file.write(\n",
    "                            f'on_clic_ana and C3 are called in {differential_time}, {differential_time_c3}  on {datetime.datetime.now()} \\n')\n",
    "            if C4.value == True:\n",
    "                save_directory = savefileD / 'Fit'\n",
    "                if BENCH == True:  # for benchmark on 2202.10.25\n",
    "                    start_time_c4 = time.perf_counter()  # for benchmark on 2202.10.25\n",
    "                d, out_l, dset_l = FEFFfit(\n",
    "                    d, checkbox_multiprocess_fit.value, checkbox_optimize_fit.value, inttext_thread_core.value)\n",
    "                if save_directory.is_dir() == False:\n",
    "                    save_directory.mkdir()\n",
    "                # THREAD_SAVE, MULTIPROCESS_FITを併用の場合はC4のFitの部分だけtnumpy.savetxtを行わないほうが処理速度が速くなるようだ\n",
    "#                if THREAD_SAVE == True != checkbox_multiprocess_fit.value : # for threading on 2023.3.23\n",
    "                if selection_data_save.value == 'TEXT':  # for threading on 2022.11.15\n",
    "                    with concurrent.futures.ThreadPoolExecutor(max_workers=inttext_thread_core.value) as executor:\n",
    "                        # CHANGED: マルチプロセス化checkbox_multiprocess_fit_value=Trueに伴いdset_lはFeffitDataSet Group形式からdict方式で出力\n",
    "                        if checkbox_multiprocess_fit.value:\n",
    "                            future_thread_savetxt = {executor.submit(_thread_savetxt, save_directory / f'Fit_{fn}',\n",
    "                                                                     ny.stack(\n",
    "                                                                         [dset['dset.data.r'], dset['dset.data.chir_mag'], dset['dset.model.r'],  dset['dset.model.chir_mag']], 1),\n",
    "                                                                     f'FT k-weight={str(dset[\"dset.transform.kweight\"])}\\nr_data chir_mag_data r_model chir_mag_model'):\n",
    "                                                     (dset, fn) for dset, fn in zip(dset_l, filenamelist)}\n",
    "                        else:\n",
    "                            future_thread_savetxt = {executor.submit(_thread_savetxt, save_directory / f'Fit_{fn}',\n",
    "                                                                     ny.stack(\n",
    "                                                                         [dset.data.r, dset.data.chir_mag, dset.model.r, dset.model.chir_mag], 1),\n",
    "                                                                     f'FT k-weight={str(dset.transform.kweight)}\\nr_data chir_mag_data r_model chir_mag_model'):\n",
    "                                                     (dset, fn) for dset, fn in zip(dset_l, filenamelist)}\n",
    "#                elif BINARY_SAVE == True:  # for save files as binary files on 2202.11.17\n",
    "                elif selection_data_save.value == 'BINARY':  # for threading on 2202.11.15\n",
    "                    binarize_data = {}\n",
    "                    header_list = []\n",
    "                    for dset, fn in zip(dset_l, filenamelist):\n",
    "                        # CHANGED: マルチプロセス化checkbox_multiprocess_fit_value=Trueに伴いdset_lはFeffitDataSet Group形式からdict方式で出力\n",
    "                        if checkbox_multiprocess_fit.value:\n",
    "                            binarize_data[f'Fit_{fn}'] = ny.stack(\n",
    "                                [dset['dset.data.r'], dset['dset.data.chir_mag'], dset['dset.model.r'],  dset['dset.model.chir_mag']], 1)\n",
    "                            header_list.append(\n",
    "                                f'FT k-weight={str(dset[\"dset.transform.kweight\"])}\\nr_data chir_mag_data r_model chir_mag_model')\n",
    "                        else:\n",
    "                            binarize_data[f'Fit_{fn}'] = ny.stack(\n",
    "                                [dset.data.r, dset.data.chir_mag, dset.model.r, dset.model.chir_mag], 1)\n",
    "                            header_list.append(\n",
    "                                f'FT k-weight={str(dset.transform.kweight)}\\nr_data chir_mag_data r_model chir_mag_model')\n",
    "                    ny.savez(save_directory /\n",
    "                             f'Fit_results.npz', **binarize_data)\n",
    "                    ny.save(save_directory / f'Fit_header.npy', header_list)\n",
    "                else:\n",
    "                    for dset, fn in zip(dset_l, filenamelist):\n",
    "                        # CHANGED: マルチプロセス化checkbox_multiprocess_fit_value=Trueに伴いdset_lはFeffitDataSet Group形式からdict方式で出力\n",
    "                        if checkbox_multiprocess_fit.value:\n",
    "                            ny.savetxt(save_directory / f'Fit_{fn}', ny.stack([dset['dset.data.r'],  dset['dset.data.chir_mag'], dset['dset.model.r'], dset['dset.model.chir_mag']], 1),\n",
    "                                       header='FT k-weight=' + str(dset['dset.transform.kweight'])+'\\nr_data chir_mag_data r_model chir_mag_model', delimiter='\\t')\n",
    "                        else:\n",
    "                            ny.savetxt(save_directory / f'Fit_{fn}', ny.stack([dset.data.r, dset.data.chir_mag, dset.model.r, dset.model.chir_mag], 1),\n",
    "                                       header='FT k-weight=' + str(dset.transform.kweight)+'\\nr_data chir_mag_data r_model chir_mag_model', delimiter='\\t')\n",
    "                print('Fit finished\\n')\n",
    "                if BENCH == True:  # for benchmark on 2202.10.25\n",
    "                    end_time = time.perf_counter()\n",
    "                    differential_time = end_time - start_time\n",
    "                    differential_time_c4 = end_time - start_time_c4\n",
    "                    with open('bench.txt', mode='a+') as bench_file:\n",
    "                        bench_file.write(\n",
    "                            f'on_clic_ana and C4 are called in {differential_time}, {differential_time_c4}  on {datetime.datetime.now()} \\n')\n",
    "            if C5.value == True:\n",
    "                if BENCH == True:\n",
    "                    start_time_c5 = time.perf_counter()  # for benchmark on 2202.10.25\n",
    "                if C4.value == False:\n",
    "                    # WARNING: マルチプロセス化checkbox_multiprocess_fit_value=Trueに伴いdset_lはFeffitDataSet Group形式からdict方式で出力\n",
    "                    d, out_l, dset_l = FEFFfit(\n",
    "                        d, checkbox_multiprocess_fit.value, checkbox_optimize_fit.value, inttext_thread_core.value)\n",
    "                No_path = read_arg3()[0]\n",
    "                HEADER_RESULTS = 's02\\te0\\tdeltar\\tsigma2\\tthird\\tfourth\\tei\\ts02_stderr\\te0_stderr\\tdeltar_stderr\\tsigma2_stderr\\tthird_stderr\\tfourth_stderr\\tei_stderr'\n",
    "                for j in range(No_path):\n",
    "                    # ny.savetxt(savefileD+'/fitting_results_path'+str(j+1)+'.dat',\\\n",
    "                    ny.savetxt(savefileD / f'fitting_results_path{str(j+1)}.dat',\n",
    "                               ny.stack([out_l[j, :, 0], out_l[j, :, 1], out_l[j, :, 2], out_l[j, :, 3], out_l[j, :, 9],\n",
    "                                         out_l[j, :, 10], out_l[j, :, 11], out_l[j,\n",
    "                                                                                 :, 5], out_l[j, :, 6], out_l[j, :, 7],\n",
    "                                         out_l[j, :, 8], out_l[j, :, 12], out_l[j, :, 13], out_l[j, :, 14]], 1),\n",
    "                               header=HEADER_RESULTS, delimiter='\\t')\n",
    "                print('Output results file finished\\n')\n",
    "                if BENCH == True:  # for benchmark on 2202.10.25\n",
    "                    end_time = time.perf_counter()\n",
    "                    differential_time = end_time - start_time\n",
    "                    differential_time_c5 = end_time - start_time_c5\n",
    "                    with open('bench.txt', mode='a+') as bench_file:\n",
    "                        bench_file.write(\n",
    "                            f'on_clic_ana and C5 are called in {differential_time}, {differential_time_c5}  on {datetime.datetime.now()} \\n')\n",
    "#            if PROFILER==True:\n",
    "            if checkbox_profiler.value == True:\n",
    "                fitall_profiler.disable()  # for profiler on 2202.10.26\n",
    "                with open(f'fitall{profiler_date.strftime(\"%Y%m%d%H%M\")}.prof', mode='a+') as fitall_profile:\n",
    "                    sortkey = SortKey.CUMULATIVE\n",
    "                    ps = pstats.Stats(\n",
    "                        fitall_profiler, stream=fitall_profile).sort_stats(sortkey)\n",
    "                    ps.print_stats()\n",
    "                    sortkey = SortKey.TIME\n",
    "                    ps = pstats.Stats(\n",
    "                        fitall_profiler, stream=fitall_profile).sort_stats(sortkey)\n",
    "                    ps.print_callers(.5, 'init')\n",
    "                    ps.print_stats(20)\n",
    "            if MEMORY_ASSESSMENT == True:  # for momory monitor on 2022.11.17\n",
    "                import sys\n",
    "                print(\"{}{: >25}{}{: >10}{}\".format(\n",
    "                    '|', 'Variable Name', '|', 'Memory', '|'))\n",
    "                print(\" ------------------------------------ \")\n",
    "                for var_name in dir():\n",
    "                    # ここだけアレンジ\n",
    "                    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 0:\n",
    "                        print(\"{}{: >25}{}{: >10}{}\".format(\n",
    "                            '|', var_name, '|', sys.getsizeof(eval(var_name)), '|'))\n",
    "        C1 = Checkbox(value=False, description='norm')\n",
    "        C2 = Checkbox(value=False, description='chik')\n",
    "        C3 = Checkbox(value=False, description='FT')\n",
    "        C4 = Checkbox(value=False, description='Fit')\n",
    "        C5 = Checkbox(value=True, description='Fitting results')\n",
    "        B1 = Button(description='start')\n",
    "        B1.on_click(on_click_ana)\n",
    "        h1 = HBox([C1, C2, C3, C4, C5])\n",
    "        ui = VBox([h1, B1])\n",
    "        display(ui)\n",
    "\n",
    "        # 評価用チェックボックス\n",
    "        layout_object = Layout(width='400px', height='40px')\n",
    "        layout_box = Layout(justify_content='flex-start')\n",
    "        cp_value = PROFILER\n",
    "        checkbox_profiler = Checkbox(\n",
    "            value=cp_value,\n",
    "            description='PROFILER: ',\n",
    "            disabled=False,\n",
    "            layout=layout_object\n",
    "        )\n",
    "        ctf_value = MULTIPROCESS_FIT\n",
    "        checkbox_multiprocess_fit = Checkbox(\n",
    "            value=ctf_value,\n",
    "            description='MULTIPROCESS_FIT: ',\n",
    "            disabled=False,\n",
    "            layout=layout_object\n",
    "        )\n",
    "        cof_value = OPTIMIZE_FIT\n",
    "        checkbox_optimize_fit = Checkbox(\n",
    "            value=cof_value,\n",
    "            description='OPTIMIZE_FIT: ',\n",
    "            disabled=False,\n",
    "            layout=layout_object\n",
    "        )\n",
    "        itf_value = MULTIPROCESS_FT_CPU_CORE\n",
    "        inttext_thread_core_ft = BoundedIntText(\n",
    "            value=itf_value,\n",
    "            description='MULTIPROCESS_FT max_workers:',\n",
    "            disabled=False,\n",
    "            min=2,\n",
    "            max=cpu_count(),\n",
    "            layout=layout_object\n",
    "\n",
    "        )\n",
    "        it_value = MULTIPROCESS_FIT_CPU_CORE\n",
    "        inttext_thread_core = BoundedIntText(\n",
    "            value=it_value,\n",
    "            description='MULTIPROCESS Fit,save max_workers:',\n",
    "            disabled=False,\n",
    "            min=2,\n",
    "            max=cpu_count(),\n",
    "            layout=layout_object\n",
    "        )\n",
    "        if BINARY_SAVE is True:\n",
    "            data_save_value = 'BINARY'\n",
    "        elif THREAD_SAVE is True:\n",
    "            data_save_value = 'TEXT'\n",
    "        selection_data_save = Select(\n",
    "            options=['BINARY', 'TEXT'],\n",
    "            value=data_save_value,\n",
    "            disable=False,\n",
    "            description='SAVE:',\n",
    "            layout=layout_object\n",
    "        )\n",
    "        inttext_thread_core_ft.style.description_width = '200px'\n",
    "        inttext_thread_core.style.description_width = '200px'\n",
    "        hbox_upper = HBox(\n",
    "            [checkbox_profiler, checkbox_multiprocess_fit, checkbox_optimize_fit])\n",
    "        hbox_bottoms = HBox(\n",
    "            [inttext_thread_core_ft, inttext_thread_core, selection_data_save])\n",
    "        vbox_options = VBox([hbox_upper, hbox_bottoms], layout=layout_box)\n",
    "        display(vbox_options)\n",
    "\n",
    "# fitting resultのグラフ描画\n",
    "\n",
    "\n",
    "class res_plot:\n",
    "    def __init__(self):\n",
    "        self.fig2 = plt.figure()\n",
    "\n",
    "        def res_plotter(select, select2, dx, path):\n",
    "            self.fig2.clear()\n",
    "            f_list, f_name_list, save_f_D = read_arg1()\n",
    "            res_list = glob.glob(save_f_D + '/fitting_results_path*.dat')\n",
    "            if len(res_list) > path:\n",
    "                data = ny.loadtxt(res_list[path], unpack=True)\n",
    "                ax1 = self.fig2.add_subplot(111)\n",
    "                x = ny.arange(len(data[:][0]))*dx\n",
    "                plotdata = data[:][select]\n",
    "                ploterror = data[:][select+7]\n",
    "                ax1.plot(x, plotdata, color='b')\n",
    "                if select2 != 7:\n",
    "                    plotdata2 = data[:][select2]\n",
    "                    ax2 = ax1.twinx()\n",
    "                    ax2.plot(x, plotdata2, color='r')\n",
    "                self.fig2.show()\n",
    "        S1 = Dropdown(options=[('S02', 0), ('enot', 1), ('deltar', 2), ('sigma2', 3), (\n",
    "            'third', 4), ('forth', 5), ('ei', 6)], value=2, description='left axis')\n",
    "        S2 = Dropdown(options=[('S02', 0), ('enot', 1), ('deltar', 2), ('sigma2', 3), (\n",
    "            'third', 4), ('forth', 5), ('ei', 6), ('none', 7)], value=7, description='right axis')\n",
    "        S3 = Dropdown(options=[('path1', 0), ('path2', 1),\n",
    "                      ('path3', 2), ('path4', 3), ('path5', 4)], value=0)\n",
    "        F1 = BoundedFloatText(value=1, min=0.000001, description='delta x')\n",
    "        ui = HBox([S3, S1, S2, F1])\n",
    "        out = interactive_output(\n",
    "            res_plotter, {'select': S1, 'select2': S2, 'dx': F1, 'path': S3})\n",
    "        display(ui, out)\n",
    "\n",
    "# データnpzファイルとヘッダーnpyファイルの解凍\n",
    "\n",
    "\n",
    "def unzip_data_pane():\n",
    "    unzip_button = Button(\n",
    "        description='Start',\n",
    "        disabled=False,\n",
    "        button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='start unzip npz file',\n",
    "        icon='check'  # (FontAwesome names without the `fa-` prefix)\n",
    "    )\n",
    "    label_unzip_button = HBox([Label(value=\"Unzip\"), unzip_button])\n",
    "    unzip_button.on_click(_unzip_data)\n",
    "    display(label_unzip_button)\n",
    "\n",
    "\n",
    "# @jit # numbaが使用できない\n",
    "def _unzip_data(button_handler):\n",
    "    # global progress_value\n",
    "    # global total_file\n",
    "    FILE_SAFIX = '_results.npz'\n",
    "    HEADER_SAFIX = '_header.npy'\n",
    "    filelist, filenamelist, savefileD = read_arg1()\n",
    "    # progress_value = 0\n",
    "    # total_file = 0\n",
    "    savefileD = Path(savefileD)\n",
    "    directories = [savefileD / prefix for prefix in PREFIXES]\n",
    "    npz_files = []\n",
    "    npy_headers = []\n",
    "    first_roop = True\n",
    "    for directory, prefix in zip(directories, PREFIXES):\n",
    "        npz_files.append(f'{directory}/{prefix}{FILE_SAFIX}')\n",
    "        npy_headers.append(f'{directory}/{prefix}{HEADER_SAFIX}')\n",
    "    for npz_file, directory, npy_header in zip(npz_files, directories, npy_headers):\n",
    "        try:\n",
    "            loaded_data = ny.load(npz_file)\n",
    "            loaded_header = ny.load(npy_header)\n",
    "            total_loaded_data = len(loaded_data)\n",
    "            if total_loaded_data == len(loaded_header):\n",
    "                _save_to_text_with_header(\n",
    "                    directory, loaded_data, loaded_header)\n",
    "                print(f'{npz_file} was finished')\n",
    "            else:\n",
    "                print(\n",
    "                    f'list length is not match between npz_file ({total_loaded_data}) and header_list ({len(loaded_header)})')\n",
    "                logger.error(\n",
    "                    f'list length is not match between npz ({total_loaded_data}) and header_list ({len(loaded_header)})')\n",
    "        except FileNotFoundError:\n",
    "            npzdataname = os.path.basename(npz_file)\n",
    "            headername = os.path.basename(npy_header)\n",
    "            print(\n",
    "                f'Not found {npzdataname} and/or {headername} ! Place {npzdataname} and/or {headername} on {directory}')\n",
    "            logger.error(\n",
    "                f'Not found {npzdataname} and/or {headername} ! Place {npzdataname} and/or {headername} on {directory}')\n",
    "\n",
    "\n",
    "@jit\n",
    "def _save_to_text_with_header(directory, loaded_npz_file, header_list):\n",
    "    for l_n, header_l in zip(loaded_npz_file, header_list):\n",
    "        ny.savetxt(f'{directory}/{l_n}',\n",
    "                   loaded_npz_file[l_n], header=header_l, delimiter='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
